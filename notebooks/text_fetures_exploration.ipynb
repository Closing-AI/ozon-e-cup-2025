{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0710d418",
   "metadata": {},
   "source": [
    "# Базовый пайплайн для соревнования по определению контрафакта "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795adc59",
   "metadata": {},
   "source": [
    "### 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da10ed03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (197198, 44)\n",
      "Test shape: (22760, 43)\n",
      "Target distribution in train:\n",
      "resolution\n",
      "0    184146\n",
      "1     13052\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "import warnings\n",
    "\n",
    "df_train = pd.read_csv('ml_ozon_сounterfeit_train.csv', index_col=0)\n",
    "df_test = pd.read_csv('ml_ozon_сounterfeit_test.csv', index_col=0)\n",
    "\n",
    "print(f\"Train shape: {df_train.shape}\")\n",
    "print(f\"Test shape: {df_test.shape}\")\n",
    "print(f\"Target distribution in train:\")\n",
    "print(df_train['resolution'].value_counts())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb4d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['description'][159385]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f2de33",
   "metadata": {},
   "source": [
    "### 2. Предобработка данных\n",
    "Используем 39 числовых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "454f9f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_columns = [col for col in numeric_columns if col != 'resolution']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "495d5047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (197198, 39)\n",
      "X_test shape: (22760, 39)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train[numeric_columns].fillna(0)\n",
    "y_train = df_train['resolution']\n",
    "X_test = df_test[numeric_columns].fillna(0)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b66346a",
   "metadata": {},
   "source": [
    "### 3. Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "492c9a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1: 0.674733\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     36830\n",
      "           1       0.89      0.54      0.67      2610\n",
      "\n",
      "    accuracy                           0.97     39440\n",
      "   macro avg       0.93      0.77      0.83     39440\n",
      "weighted avg       0.96      0.97      0.96     39440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train[numeric_columns].fillna(0)\n",
    "y_train = df_train['resolution']\n",
    "X_test = df_test[numeric_columns].fillna(0)\n",
    "\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "val_pred = model.predict(X_val_split)\n",
    "val_f1 = f1_score(y_val_split, val_pred, pos_label=1)\n",
    "\n",
    "print(f\"Validation f1: {val_f1:.6f}\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_val_split, val_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00348144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (197198, 39)\n",
      "\n",
      "Validation f1: 0.678224\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     36830\n",
      "           1       0.89      0.55      0.68      2610\n",
      "\n",
      "    accuracy                           0.97     39440\n",
      "   macro avg       0.93      0.77      0.83     39440\n",
      "weighted avg       0.96      0.97      0.96     39440\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train[numeric_columns].fillna(-1)\n",
    "y_train = df_train['resolution']\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print()\n",
    "\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "val_pred = model.predict(X_val_split)\n",
    "val_f1 = f1_score(y_val_split, val_pred, pos_label=1)\n",
    "\n",
    "print(f\"Validation f1: {val_f1:.6f}\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_val_split, val_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4785f1cb",
   "metadata": {},
   "source": [
    "### 4. Формирование submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb33221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создан файл submission.csv с 22760 предсказаниями\n",
      "Распределение предсказаний:\n",
      "prediction\n",
      "0    22450\n",
      "1      310\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': df_test.index,\n",
    "    'prediction': test_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "\n",
    "print(f\"Создан файл submission.csv с {len(submission)} предсказаниями\")\n",
    "print(f\"Распределение предсказаний:\")\n",
    "print(submission['prediction'].value_counts())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16954fd4",
   "metadata": {},
   "source": [
    "# exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb77940e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['resolution', 'brand_name', 'description', 'name_rus',\n",
       "       'CommercialTypeName4', 'rating_1_count', 'rating_2_count',\n",
       "       'rating_3_count', 'rating_4_count', 'rating_5_count',\n",
       "       'comments_published_count', 'photos_published_count',\n",
       "       'videos_published_count', 'PriceDiscounted', 'item_time_alive',\n",
       "       'item_count_fake_returns7', 'item_count_fake_returns30',\n",
       "       'item_count_fake_returns90', 'item_count_sales7', 'item_count_sales30',\n",
       "       'item_count_sales90', 'item_count_returns7', 'item_count_returns30',\n",
       "       'item_count_returns90', 'GmvTotal7', 'GmvTotal30', 'GmvTotal90',\n",
       "       'ExemplarAcceptedCountTotal7', 'ExemplarAcceptedCountTotal30',\n",
       "       'ExemplarAcceptedCountTotal90', 'OrderAcceptedCountTotal7',\n",
       "       'OrderAcceptedCountTotal30', 'OrderAcceptedCountTotal90',\n",
       "       'ExemplarReturnedCountTotal7', 'ExemplarReturnedCountTotal30',\n",
       "       'ExemplarReturnedCountTotal90', 'ExemplarReturnedValueTotal7',\n",
       "       'ExemplarReturnedValueTotal30', 'ExemplarReturnedValueTotal90',\n",
       "       'ItemVarietyCount', 'ItemAvailableCount', 'seller_time_alive', 'ItemID',\n",
       "       'SellerID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bd059ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Мешки для пылесоса PHILIPS TRIATLON, синтетические, многослойные, тип: HR 6947'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['name_rus'][159385]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c548f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACTRUM'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['brand_name'][159385]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c2156d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Мешки пылесборники для пылесоса PHILIPS, 10 шт., синтетические, многослойные, бренд: ACTRUM, арт. AK-10/10, тип оригинального мешка: HR 6947.Подходят для пылесосов:PHILIPS: HR6955, HR6947, HR6888, HR6844 TRIATHLON, HR6843 TRIATHLON, HR6842 TRIATHLON, HR6841 TRIATHLON, HR6840 TRIATHLON, HR6839 TRIATHLON, HR6838 TRIATHLON, HR6837 TRIATHLON, HR6836 TRIATHLON, HR6835 TRIATHLON, HR6834 TRIATHLON, HR6833 TRIATHLON, HR6832 TRIATHLON, HR6831 TRIATHLON, HR6830 TRIATHLON, HR6829 TRIATHLON, HR6828 TRIATHLON, HR6827 TRIATHLON, HR6826 TRIATHLON, HR6825 TRIATHLON, HR6824 TRIATHLON, HR6823 TRIATHLON, HR6822 TRIATHLON, HR6821 TRIATHLON, HR6820 TRIATHLON, HR6819 TRIATHLON, HR6818 TRIATHLON, HR6817 TRIATHLON, HR6816 TRIATHLON, HR6815 TRIATHLON, HR6814 - HR6845 TRIATHLON, FC6844 TRIATHLON, FC6843 TRIATHLON, FC6842 TRIATHLON, FC6841 - FC6845 TRIATHLONОдноразовые мешки-пылесборники ACTRUM изгот'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['description'][159385]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1f11161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Пылесборник'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['CommercialTypeName4'][159385]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c69ba93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197198"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcd8efe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных брендов: 4066\n",
      "Пропущенных брендов: 80531\n"
     ]
    }
   ],
   "source": [
    "unique_brands = df_train[\"brand_name\"].nunique(dropna=True)\n",
    "missing_brands = df_train[\"brand_name\"].isna().sum()\n",
    "\n",
    "print(f\"Уникальных брендов: {unique_brands}\")\n",
    "print(f\"Пропущенных брендов: {missing_brands}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c908a140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных описаний: 114781\n",
      "Пропущенных описаний: 26060\n"
     ]
    }
   ],
   "source": [
    "unique_brands = df_train[\"description\"].nunique(dropna=True)\n",
    "missing_brands = df_train[\"description\"].isna().sum()\n",
    "\n",
    "print(f\"Уникальных описаний: {unique_brands}\")\n",
    "print(f\"Пропущенных описаний: {missing_brands}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0da8ce5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных карточек: 154718\n",
      "Пропущенных карточек: 0\n"
     ]
    }
   ],
   "source": [
    "unique_brands = df_train[\"name_rus\"].nunique(dropna=True)\n",
    "missing_brands = df_train[\"name_rus\"].isna().sum()\n",
    "\n",
    "print(f\"Уникальных карточек: {unique_brands}\")\n",
    "print(f\"Пропущенных карточек: {missing_brands}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "594f627c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных ком названий: 634\n",
      "Пропущенных ком названий: 0\n"
     ]
    }
   ],
   "source": [
    "unique_brands = df_train[\"CommercialTypeName4\"].nunique(dropna=True)\n",
    "missing_brands = df_train[\"CommercialTypeName4\"].isna().sum()\n",
    "\n",
    "print(f\"Уникальных ком названий: {unique_brands}\")\n",
    "print(f\"Пропущенных ком названий: {missing_brands}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2795bdf7",
   "metadata": {},
   "source": [
    "# Функции очищения текстовых данных и создание фич."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f844a9d",
   "metadata": {},
   "source": [
    "## простые фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7e5aeeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "import unicodedata\n",
    "\n",
    "# --- regex patterns ---\n",
    "INVISIBLE_RE = re.compile(\n",
    "    r\"[\\u200B-\\u200F\\u202A-\\u202E\\u2060-\\u206F\\uFEFF\\uFFF9-\\uFFFB]\"\n",
    ")\n",
    "CONTROL_RE = re.compile(r\"[\\x00-\\x1F\\x7F]\")\n",
    "TAG_RE = re.compile(r\"<[^>]+>\")\n",
    "WS_RE = re.compile(r\"\\s+\")\n",
    "URL_PATTERN = re.compile(r\"(https?://\\S+|www\\.\\S+)\", re.IGNORECASE)\n",
    "\n",
    "# --- cleaning functions ---\n",
    "def unescape_html(text: str) -> str:\n",
    "    return html.unescape(text) if isinstance(text, str) else \"\"\n",
    "\n",
    "def replace_specific_tags(text: str) -> str:\n",
    "    return re.sub(r\"(?i)</?(br|p|li|ul|ol|div|span)\\b[^>]*>\", \" \", text) if isinstance(text, str) else text\n",
    "\n",
    "def remove_html_tags(text: str) -> str:\n",
    "    return TAG_RE.sub(\" \", text) if isinstance(text, str) else text\n",
    "\n",
    "def remove_invisible_chars(text: str) -> str:\n",
    "    return INVISIBLE_RE.sub(\"\", text) if isinstance(text, str) else text\n",
    "\n",
    "def replace_control_chars(text: str) -> str:\n",
    "    return CONTROL_RE.sub(\" \", text) if isinstance(text, str) else text\n",
    "\n",
    "def replace_special_chars(text: str) -> str:\n",
    "    return re.sub(r\"[•‣‥∙]\", \" \", text) if isinstance(text, str) else text\n",
    "\n",
    "def collapse_whitespace(text: str) -> str:\n",
    "    return WS_RE.sub(\" \", text).strip() if isinstance(text, str) else text\n",
    "\n",
    "def normalize_urls(text: str) -> str:\n",
    "    def normalize_url(match):\n",
    "        url = match.group(0)\n",
    "        return url.split(\"?\")[0]\n",
    "    return URL_PATTERN.sub(normalize_url, text) if isinstance(text, str) else text\n",
    "\n",
    "# --- dictionary of cleaning functions ---\n",
    "CLEANING_FUNCTIONS = {\n",
    "    \"unescape_html\": unescape_html,\n",
    "    \"replace_specific_tags\": replace_specific_tags,\n",
    "    \"remove_html_tags\": remove_html_tags,\n",
    "    \"remove_invisible_chars\": remove_invisible_chars,\n",
    "    \"replace_control_chars\": replace_control_chars,\n",
    "    \"replace_special_chars\": replace_special_chars,\n",
    "    \"collapse_whitespace\": collapse_whitespace,\n",
    "    \"normalize_urls\": normalize_urls,\n",
    "}\n",
    "\n",
    "# --- main cleaner ---\n",
    "def basic_clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Applies a series of cleaning functions to the input text in sequence.\n",
    "    Returns the cleaned text.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    result = text\n",
    "    for name, func in CLEANING_FUNCTIONS.items():\n",
    "        result = func(result)\n",
    "    return result\n",
    "\n",
    "def create_basic_cleaned_text(text_series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Возвращает очищенную последовательность\"\"\"\n",
    "    return text_series.apply(basic_clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8899c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "159385    Мешки пылесборники для пылесоса PHILIPS, 10 шт...\n",
       "288616    Защитная силиконовая крышка обьектива GoPro He...\n",
       "108090    Плоский медиатор из кости толщиной 0.6 мм Плос...\n",
       "415607    Игра Sonic Frontiers для PlayStation 5, русски...\n",
       "332391    Disney Classic Games: Aladdin and The Lion Kin...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример проверки\n",
    "description = df_train['description']\n",
    "clened_description = create_basic_cleaned_text(description)\n",
    "clened_description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502b7fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_capslock_words(text: str) -> int:\n",
    "    return sum(\n",
    "        1\n",
    "        for word in text.split()\n",
    "        if word.isalpha()\n",
    "        and word.isupper()\n",
    "        and len(word) > 5\n",
    "        and not any(ch.isdigit() for ch in word)\n",
    "    )\n",
    "\n",
    "# --- regex patterns ---\n",
    "URL_PATTERN = re.compile(r\"(https?://\\S+|www\\.\\S+)\", re.IGNORECASE)\n",
    "PHONE_PATTERN = re.compile(\n",
    "    r\"(?<!\\d)(?:\\+7|8)\\s*[\\-]?\\s*\\(?\\d{3}\\)?\\s*[\\-]?\\s*\\d{3}\\s*[\\-]?\\s*\\d{2}\\s*[\\-]?\\s*\\d{2}(?!\\d)\"\n",
    ")\n",
    "SKU_PATTERN = re.compile(r\"\\b(?:[A-ZА-Я0-9]{5,15})\\b\")\n",
    "PRICE_PATTERN = re.compile(r\"\\b\\d{1,6}\\s*(?:руб|р|₽)\\b\", re.IGNORECASE)\n",
    "EMOJI_PATTERN = re.compile(\n",
    "    r'[\\U0001F600-\\U0001F64F'\n",
    "    r'\\U0001F300-\\U0001F5FF'\n",
    "    r'\\U0001F680-\\U0001F6FF'\n",
    "    r'\\U0001F1E0-\\U0001F1FF'\n",
    "    r'\\U00002702-\\U000027B0'\n",
    "    r'\\U000024C2-\\U0001F251]+'\n",
    ")\n",
    "MESSENGERS = [\n",
    "    \"whatsapp\", \"telegram\", \"viber\", \"wechat\", \"signal\", \"icq\", \"вк\",\n",
    "    \"вконтакте\", \"телеграм\", \" телега\", \"тг\", \"тгк\", \"instagram\",\n",
    "    \"инст\", \"инста\", \"инстаграм\"\n",
    "]\n",
    "\n",
    "# --- feature functions ---\n",
    "def has_url(text: str): return int(bool(URL_PATTERN.search(text)))\n",
    "def has_phone(text: str): return int(bool(PHONE_PATTERN.search(text)))\n",
    "def has_messenger(text: str): return int(any(re.search(rf\"\\b{re.escape(m)}\\b\", text.lower()) for m in MESSENGERS))\n",
    "def has_sku(text: str): return int(bool(SKU_PATTERN.search(text)))\n",
    "def desc_len_chars(text: str): return len(text)\n",
    "def desc_len_words(text: str): return len(text.split())\n",
    "def capslock_word_count(text: str): return count_capslock_words(text)\n",
    "def exclamation_count(text: str): return text.count('!') + text.count('‼')\n",
    "def question_count(text: str): return text.count('?')\n",
    "def avg_word_length(text: str):\n",
    "    words = text.split()\n",
    "    return sum(len(word) for word in words) / len(words) if words else 0.0\n",
    "def has_price(text: str): return int(bool(PRICE_PATTERN.search(text)))\n",
    "def upper_ratio(text: str):\n",
    "    letters = [ch for ch in text if ch.isalpha()]\n",
    "    return sum(1 for ch in letters if ch.isupper()) / len(letters) if letters else 0.0\n",
    "def has_emoji(text: str): return int(bool(EMOJI_PATTERN.search(text)))\n",
    "def emoji_count(text: str): return len(EMOJI_PATTERN.findall(text))\n",
    "\n",
    "\n",
    "# --- dictionary of features ---\n",
    "FEATURE_FUNCTIONS = {\n",
    "    \"has_url\": has_url,\n",
    "    # \"has_phone\": has_phone,\n",
    "    \"has_messenger\": has_messenger,\n",
    "    \"has_sku\": has_sku,\n",
    "    \"desc_len_chars\": desc_len_chars,\n",
    "    \"desc_len_words\": desc_len_words,\n",
    "    \"capslock_word_count\": capslock_word_count,\n",
    "    \"exclamation_count\": exclamation_count,\n",
    "    \"question_count\": question_count,\n",
    "    \"avg_word_length\": avg_word_length,\n",
    "    \"has_price\": has_price,\n",
    "    \"upper_ratio\": upper_ratio,\n",
    "    \"has_emoji\": has_emoji,\n",
    "    \"emoji_count\": emoji_count,\n",
    "}\n",
    "\n",
    "\n",
    "# --- main extractor ---\n",
    "def extract_basic_text_features(text: str):\n",
    "    if not isinstance(text, str):\n",
    "        return {name: 0 if \"ratio\" not in name and \"avg\" not in name else 0.0 for name in FEATURE_FUNCTIONS}\n",
    "\n",
    "    return {name: func(text) for name, func in FEATURE_FUNCTIONS.items()}\n",
    "\n",
    "\n",
    "def create_basic_text_features(text_series: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Takes a pandas Series of texts and returns a DataFrame with extracted features. Index preserved.\n",
    "    \"\"\"\n",
    "    features_df = text_series.apply(extract_basic_text_features).apply(pd.Series)\n",
    "    features_df.index = text_series.index\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f28c7838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_url</th>\n",
       "      <th>has_phone</th>\n",
       "      <th>has_messenger</th>\n",
       "      <th>has_sku</th>\n",
       "      <th>desc_len_chars</th>\n",
       "      <th>desc_len_words</th>\n",
       "      <th>capslock_word_count</th>\n",
       "      <th>exclamation_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>has_price</th>\n",
       "      <th>upper_ratio</th>\n",
       "      <th>has_emoji</th>\n",
       "      <th>emoji_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159385</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.870000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.761566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288616</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.301887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108090</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415607</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.328358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332391</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.728571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        has_url  has_phone  has_messenger  has_sku  desc_len_chars  \\\n",
       "id                                                                   \n",
       "159385      0.0        0.0            0.0      1.0           886.0   \n",
       "288616      0.0        0.0            0.0      0.0           386.0   \n",
       "108090      0.0        0.0            0.0      0.0           200.0   \n",
       "415607      0.0        0.0            0.0      0.0           557.0   \n",
       "332391      0.0        0.0            0.0      0.0           540.0   \n",
       "\n",
       "        desc_len_words  capslock_word_count  exclamation_count  \\\n",
       "id                                                               \n",
       "159385           100.0                  1.0                0.0   \n",
       "288616            53.0                  0.0                0.0   \n",
       "108090            33.0                  0.0                0.0   \n",
       "415607            67.0                  0.0                0.0   \n",
       "332391            70.0                  0.0                0.0   \n",
       "\n",
       "        question_count  avg_word_length  has_price  upper_ratio  has_emoji  \\\n",
       "id                                                                           \n",
       "159385             0.0         7.870000        0.0     0.761566        0.0   \n",
       "288616             0.0         6.301887        0.0     0.018634        0.0   \n",
       "108090             0.0         5.090909        0.0     0.040268        0.0   \n",
       "415607             0.0         7.328358        0.0     0.027197        0.0   \n",
       "332391             0.0         6.728571        0.0     0.037778        0.0   \n",
       "\n",
       "        emoji_count  \n",
       "id                   \n",
       "159385          0.0  \n",
       "288616          0.0  \n",
       "108090          0.0  \n",
       "415607          0.0  \n",
       "332391          0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_text_features = create_basic_text_features(clened_description)\n",
    "basic_text_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c4184e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['has_url', 'has_phone', 'has_messenger', 'has_sku', 'desc_len_chars',\n",
       "       'desc_len_words', 'capslock_word_count', 'exclamation_count',\n",
       "       'question_count', 'avg_word_length', 'has_price', 'upper_ratio',\n",
       "       'has_emoji', 'emoji_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_text_features.columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80b3cbe1",
   "metadata": {},
   "source": [
    "Дальнейший план:\n",
    "1) Придумать еще пару фич\n",
    "2) Леммитизация, стемминг \n",
    "3) tf-idf\n",
    "4) Обучить рандомный лес, сравнить точность с текстовыми данными и без.\n",
    "5) n-gramm\n",
    "6) Обучить логрегрессию, mlp\n",
    "7) Подумать над категориальными признаками (хэш, seller_id)\n",
    "8) подумать над  null\n",
    "9) созвон с Денчиком"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea9fee4",
   "metadata": {},
   "source": [
    "## семантика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d35089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from razdel import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy3\n",
    "from functools import lru_cache\n",
    "import nltk\n",
    "\n",
    "# Initialize resources\n",
    "nltk.download('stopwords', quiet=True)\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "# Cache lemmatization results\n",
    "@lru_cache(maxsize=10000)\n",
    "def cached_lemmatize(token: str) -> str:\n",
    "    \"\"\"Cached lemmatization using pymorphy3.\"\"\"\n",
    "    return morph.parse(token)[0].normal_form\n",
    "\n",
    "# --- regex patterns ---\n",
    "COMBINED_PATTERN = re.compile(\n",
    "    r\"(https?://\\S+|www\\.\\S+|\"\n",
    "    r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF'\n",
    "    r'\\U0001F1E0-\\U0001F1FF\\U00002702-\\U000027B0\\U000024C2-\\U0001F251]+|'\n",
    "    r\"\\b\\d+\\b|[^\\w\\s])\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "WS_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "# Stop words\n",
    "STOP_WORDS = set(stopwords.words(\"russian\"))\n",
    "\n",
    "# --- cleaning functions ---\n",
    "def lowercase_text(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Convert text to lowercase (vectorized).\"\"\"\n",
    "    return series.str.lower()\n",
    "\n",
    "def normalize_unicode(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Normalize Unicode characters to NFKC form (vectorized).\"\"\"\n",
    "    return series.apply(lambda x: unicodedata.normalize(\"NFKC\", x) if isinstance(x, str) else \"\")\n",
    "\n",
    "def remove_combined_patterns(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Remove URLs, emojis, numbers, and punctuation in one pass.\"\"\"\n",
    "    return series.str.replace(COMBINED_PATTERN, \" \", regex=True)\n",
    "\n",
    "def collapse_whitespace(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Collapse multiple whitespaces into a single space (vectorized).\"\"\"\n",
    "    return series.str.replace(WS_RE, \" \", regex=True).str.strip()\n",
    "\n",
    "def tokenize_text(text: str) -> list:\n",
    "    \"\"\"Tokenize text into words using razdel.\"\"\"\n",
    "    if not isinstance(text, str) or text == \"\":\n",
    "        return []\n",
    "    return [token.text for token in tokenize(text)]\n",
    "\n",
    "def lemmatize_and_filter(tokens: list) -> list:\n",
    "    \"\"\"Lemmatize tokens, filter out non-alphabetic tokens and stop words.\"\"\"\n",
    "    if not tokens:\n",
    "        return []\n",
    "    return [\n",
    "        cached_lemmatize(token)\n",
    "        for token in tokens\n",
    "        if token.isalpha() and token not in STOP_WORDS\n",
    "    ]\n",
    "\n",
    "def remove_consecutive_duplicates(tokens: list) -> list:\n",
    "    \"\"\"Remove consecutive duplicate words from the token list.\"\"\"\n",
    "    if not tokens:\n",
    "        return []\n",
    "    result = [tokens[0]]\n",
    "    for i in range(1, len(tokens)):\n",
    "        if tokens[i] != tokens[i-1]:\n",
    "            result.append(tokens[i])\n",
    "    return result\n",
    "\n",
    "def join_tokens(tokens: list) -> str:\n",
    "    \"\"\"Join tokens back into a string with spaces.\"\"\"\n",
    "    return \" \".join(tokens) if tokens else \"\"\n",
    "\n",
    "# --- per-text cleaning function ---\n",
    "def clean_text_semantic_single(text: str) -> str:\n",
    "    \"\"\"Process a single text through tokenization, lemmatization, and duplicate removal.\"\"\"\n",
    "    if not isinstance(text, str) or text == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = tokenize_text(text)\n",
    "    \n",
    "    # Lemmatize and filter\n",
    "    tokens = lemmatize_and_filter(tokens)\n",
    "    \n",
    "    # Remove consecutive duplicates\n",
    "    tokens = remove_consecutive_duplicates(tokens)\n",
    "    \n",
    "    # Join tokens\n",
    "    return join_tokens(tokens)\n",
    "\n",
    "# --- dictionary of vectorized cleaning functions ---\n",
    "VECTORIZED_CLEANING_FUNCTIONS = {\n",
    "    \"lowercase_text\": lowercase_text,\n",
    "    \"normalize_unicode\": normalize_unicode,\n",
    "    \"remove_combined_patterns\": remove_combined_patterns,\n",
    "    \"collapse_whitespace\": collapse_whitespace,\n",
    "}\n",
    "\n",
    "# --- main cleaner ---\n",
    "def create_semantic_cleaned_text(text_series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Returns a semantically cleaned pandas Series by applying vectorized and sequential cleaning steps.\n",
    "    \n",
    "    Args:\n",
    "        text_series (pd.Series): Input Series of texts.\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series: Cleaned text Series with the same index.\n",
    "    \"\"\"\n",
    "    if not isinstance(text_series, pd.Series):\n",
    "        raise ValueError(\"Input must be a pandas Series\")\n",
    "\n",
    "    # Apply vectorized operations\n",
    "    result = text_series\n",
    "    for name, func in VECTORIZED_CLEANING_FUNCTIONS.items():\n",
    "        result = func(result)\n",
    "    \n",
    "    # Apply tokenization, lemmatization, and duplicate removal\n",
    "    cleaned_texts = result.apply(clean_text_semantic_single)\n",
    "    \n",
    "    # Return as Series with original index\n",
    "    return pd.Series(cleaned_texts, index=text_series.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdd1c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_cleaned_text = create_semantic_cleaned_text(clened_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df5bada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_semantic_cleaned_text = create_semantic_cleaned_text(clened_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58c5a068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "159385    мешок пылесборник пылесос philips шт синтетиче...\n",
       "288616    защитный силиконовый крышка обьектив gopro her...\n",
       "108090    плоский медиатор кость толщина мм плоский меди...\n",
       "415607    игра sonic frontiers playstation русский субти...\n",
       "332391    disney classic games aladdin and the lion king...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_semantic_cleaned_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f99f8d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Защитная силиконовая крышка обьектива GoPro Hero 5 / 6 / 7 - это незаменимый аксессуар для каждого владельца вышеупомянутых экшн-камер. Данная крышка рассчитана для защиты линзы объектива от грязи, пыли и царапин при хранении или переноски камеры. Изготовленная при использовании качественного материала, это крышка обладает высокой степенью прочности и прослужит вам максимально долго.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clened_description[288616]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "940da93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'защитный силиконовый крышка обьектив gopro hero это незаменимый аксессуар каждый владелец вышеупомянутый экшн камера дать крышка рассчитать защита линза объектив грязь пыль царапина хранение переноска камера изготовить использование качественный материал это крышка обладать высокий степень прочность прослужить максимально долго'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_semantic_cleaned_text[288616]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5410d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- semantic lexicons ---\n",
    "SUSPICIOUS_WORDS = {\n",
    "    \"реплика\", \"копия\", \"аналог\", \"подделка\", \"реселл\", \"фейк\",\n",
    "    \"контрафакт\", \"дешево\", \"скидка\", \"акция\", \"оригинал\", \"коробка\", \"оригинальный\",\n",
    "    \"позвонить\", \"написать\", \"перепродажа\"\n",
    "}\n",
    "BRANDS = {\n",
    "    \"nike\", \"adidas\", \"gucci\", \"apple\", \"samsung\", \"rolex\",\n",
    "    \"louisvuitton\", \"chanel\", \"prada\", \"reebok\", \"philips\", \"apple\", \"logitech\"\n",
    "}\n",
    "URGENCY_WORDS = {\n",
    "    \"срочно\", \"быстро\", \"спешить\", \"поспешить\", \"ограниченный\",\n",
    "    \"последний\", \"сегодня\", \"немедленно\",\n",
    "}\n",
    "\n",
    "# --- feature functions ---\n",
    "def has_suspicious_words(text: str):\n",
    "    words = text.split()\n",
    "    return int(any(word in SUSPICIOUS_WORDS for word in words))\n",
    "\n",
    "def suspicious_word_count(text: str):\n",
    "    words = text.split()\n",
    "    return sum(1 for word in words if word in SUSPICIOUS_WORDS)\n",
    "\n",
    "def has_brand(text: str):\n",
    "    words = text.split()\n",
    "    return int(any(word in BRANDS for word in words))\n",
    "\n",
    "def brand_count(text: str):\n",
    "    words = text.split()\n",
    "    return sum(1 for word in words if word in BRANDS)\n",
    "\n",
    "def has_urgency_words(text: str):\n",
    "    words = text.split()\n",
    "    return int(any(word in URGENCY_WORDS for word in words))\n",
    "\n",
    "def urgency_word_count(text: str):\n",
    "    words = text.split()\n",
    "    return sum(1 for word in words if word in URGENCY_WORDS)\n",
    "\n",
    "def unique_word_ratio(text: str):\n",
    "    words = text.split()\n",
    "    return len(set(words)) / len(words) if words else 0.0\n",
    "\n",
    "\n",
    "# --- dictionary of semantic features ---\n",
    "SEMANTIC_FEATURE_FUNCTIONS = {\n",
    "    \"has_suspicious_words\": has_suspicious_words,\n",
    "    \"suspicious_word_count\": suspicious_word_count,\n",
    "    # \"has_brand\": has_brand,\n",
    "    \"brand_count\": brand_count,\n",
    "    \"has_urgency_words\": has_urgency_words,\n",
    "    \"urgency_word_count\": urgency_word_count,\n",
    "    \"unique_word_ratio\": unique_word_ratio,\n",
    "}\n",
    "\n",
    "\n",
    "# --- main extractor ---\n",
    "def extract_semantic_features(text: str) -> dict:\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        # zeros for counts, 0.0 for ratios\n",
    "        return {\n",
    "            name: 0 if \"ratio\" not in name else 0.0\n",
    "            for name in SEMANTIC_FEATURE_FUNCTIONS\n",
    "        }\n",
    "    return {name: func(text) for name, func in SEMANTIC_FEATURE_FUNCTIONS.items()}\n",
    "\n",
    "\n",
    "def create_semantic_features(text_series: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Takes a pandas Series of pre-cleaned texts and returns a DataFrame with semantic features.\n",
    "    Index is preserved.\n",
    "    \"\"\"\n",
    "    features_df = text_series.apply(extract_semantic_features).apply(pd.Series)\n",
    "    features_df.index = text_series.index\n",
    "    return features_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3402d3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_suspicious_words</th>\n",
       "      <th>suspicious_word_count</th>\n",
       "      <th>has_brand</th>\n",
       "      <th>brand_count</th>\n",
       "      <th>has_urgency_words</th>\n",
       "      <th>urgency_word_count</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159385</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288616</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.897436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108090</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415607</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332391</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.847458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        has_suspicious_words  suspicious_word_count  has_brand  brand_count  \\\n",
       "id                                                                            \n",
       "159385                   1.0                    1.0        1.0          2.0   \n",
       "288616                   0.0                    0.0        0.0          0.0   \n",
       "108090                   0.0                    0.0        0.0          0.0   \n",
       "415607                   0.0                    0.0        0.0          0.0   \n",
       "332391                   0.0                    0.0        0.0          0.0   \n",
       "\n",
       "        has_urgency_words  urgency_word_count  unique_word_ratio  \n",
       "id                                                                \n",
       "159385                0.0                 0.0           0.315789  \n",
       "288616                0.0                 0.0           0.897436  \n",
       "108090                0.0                 0.0           0.666667  \n",
       "415607                0.0                 0.0           0.927273  \n",
       "332391                0.0                 0.0           0.847458  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_text_features = create_semantic_features(semantic_cleaned_text)\n",
    "semantic_text_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db007b1",
   "metadata": {},
   "source": [
    "### проверка бинарных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "71b380d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_ratios_for_binary_features(\n",
    "    df_train: pd.DataFrame,\n",
    "    basic_text_features: pd.DataFrame,\n",
    "    semantic_text_features: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates the class ratios for binary features where the feature value = 1.\n",
    "    Combines basic and semantic features, adds the target 'resolution', and computes:\n",
    "    - Overall class 1 ratio\n",
    "    - Conditional class 1 ratio for each binary feature = 1\n",
    "    - Lift (conditional ratio / overall ratio)\n",
    "    - Support (number of instances where feature = 1)\n",
    "    - Total number of instances\n",
    "\n",
    "    Args:\n",
    "        df_train (pd.DataFrame): DataFrame containing the target 'resolution' (0 or 1).\n",
    "        basic_text_features (pd.DataFrame): DataFrame with basic text features.\n",
    "        semantic_text_features (pd.DataFrame): DataFrame with semantic text features.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with the calculated metrics for each binary feature.\n",
    "    \"\"\"\n",
    "    # Combine features from basic and semantic\n",
    "    all_features = pd.concat([basic_text_features, semantic_text_features], axis=1)\n",
    "    \n",
    "    # Add target column\n",
    "    df = pd.concat([all_features, df_train['resolution']], axis=1)\n",
    "    \n",
    "    # List of binary features (has_ prefixed)\n",
    "    binary_features = [\n",
    "        'has_suspicious_words', 'has_brand', 'has_urgency_words',\n",
    "        'has_url', 'has_phone', 'has_messenger', 'has_sku',\n",
    "        'has_price', 'has_emoji'\n",
    "    ]\n",
    "    \n",
    "    # Ensure all binary features exist in the DataFrame\n",
    "    missing_features = [feat for feat in binary_features if feat not in df.columns]\n",
    "    if missing_features:\n",
    "        raise ValueError(f\"Missing binary features: {missing_features}\")\n",
    "    \n",
    "    # Overall class 1 ratio\n",
    "    overall_ratio = df['resolution'].mean()\n",
    "    total_count = len(df)\n",
    "    \n",
    "    # Prepare results list\n",
    "    results = []\n",
    "    \n",
    "    for feat in binary_features:\n",
    "        # Subset where feature = 1\n",
    "        subset = df[df[feat] == 1]\n",
    "        support = len(subset)\n",
    "        \n",
    "        if support > 0:\n",
    "            conditional_ratio = subset['resolution'].mean()\n",
    "            lift = conditional_ratio / overall_ratio if overall_ratio > 0 else float('inf')\n",
    "        else:\n",
    "            conditional_ratio = None\n",
    "            lift = None\n",
    "        \n",
    "        results.append({\n",
    "            'feature': feat,\n",
    "            'overall_ratio': overall_ratio,\n",
    "            'conditional_ratio': conditional_ratio,\n",
    "            'lift': lift,\n",
    "            'support': support,\n",
    "            'total_count': total_count\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Print overall ratio once\n",
    "    print(f\"Overall class 1 ratio: {overall_ratio:.4f} (Total instances: {total_count})\")\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e8c450f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall class 1 ratio: 0.0662 (Total instances: 197198)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>overall_ratio</th>\n",
       "      <th>conditional_ratio</th>\n",
       "      <th>lift</th>\n",
       "      <th>support</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>has_suspicious_words</td>\n",
       "      <td>0.066187</td>\n",
       "      <td>0.082569</td>\n",
       "      <td>1.247503</td>\n",
       "      <td>1417</td>\n",
       "      <td>197198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>has_brand</td>\n",
       "      <td>0.066187</td>\n",
       "      <td>0.064433</td>\n",
       "      <td>0.973495</td>\n",
       "      <td>388</td>\n",
       "      <td>197198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>has_urgency_words</td>\n",
       "      <td>0.066187</td>\n",
       "      <td>0.123792</td>\n",
       "      <td>1.870322</td>\n",
       "      <td>4241</td>\n",
       "      <td>197198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>has_url</td>\n",
       "      <td>0.066187</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>6.043457</td>\n",
       "      <td>10</td>\n",
       "      <td>197198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>has_phone</td>\n",
       "      <td>0.066187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>197198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>has_messenger</td>\n",
       "      <td>0.066187</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>0.271413</td>\n",
       "      <td>167</td>\n",
       "      <td>197198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>has_sku</td>\n",
       "      <td>0.066187</td>\n",
       "      <td>0.044599</td>\n",
       "      <td>0.673827</td>\n",
       "      <td>91998</td>\n",
       "      <td>197198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>has_price</td>\n",
       "      <td>0.066187</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>1.753682</td>\n",
       "      <td>560</td>\n",
       "      <td>197198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>has_emoji</td>\n",
       "      <td>0.066187</td>\n",
       "      <td>0.111444</td>\n",
       "      <td>1.683764</td>\n",
       "      <td>3006</td>\n",
       "      <td>197198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature  overall_ratio  conditional_ratio      lift  support  \\\n",
       "0  has_suspicious_words       0.066187           0.082569  1.247503     1417   \n",
       "1             has_brand       0.066187           0.064433  0.973495      388   \n",
       "2     has_urgency_words       0.066187           0.123792  1.870322     4241   \n",
       "3               has_url       0.066187           0.400000  6.043457       10   \n",
       "4             has_phone       0.066187           0.000000  0.000000       19   \n",
       "5         has_messenger       0.066187           0.017964  0.271413      167   \n",
       "6               has_sku       0.066187           0.044599  0.673827    91998   \n",
       "7             has_price       0.066187           0.116071  1.753682      560   \n",
       "8             has_emoji       0.066187           0.111444  1.683764     3006   \n",
       "\n",
       "   total_count  \n",
       "0       197198  \n",
       "1       197198  \n",
       "2       197198  \n",
       "3       197198  \n",
       "4       197198  \n",
       "5       197198  \n",
       "6       197198  \n",
       "7       197198  \n",
       "8       197198  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_class_ratios_for_binary_features(df_train, semantic_text_features, basic_text_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007db0a2",
   "metadata": {},
   "source": [
    "## Фичи tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fde5627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def create_tfidf_features(\n",
    "    texts_char: pd.Series,\n",
    "    texts_word: pd.Series,\n",
    "    mode: str = 'train',\n",
    "    tfidf_char_vectorizer=None,\n",
    "    tfidf_word_vectorizer=None,\n",
    "    max_tfidf_features: int = 1000,\n",
    "    char_ngram_range: tuple = (3, 5),\n",
    "    word_ngram_range: tuple = (1, 3)\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Creates TF-IDF features for character and word n-grams from two separate pandas Series of texts.\n",
    "    For 'train' mode, fits and transforms the TF-IDF vectorizers.\n",
    "    For 'test' mode, only transforms using the provided fitted vectorizers.\n",
    "\n",
    "    Args:\n",
    "        texts_char (pd.Series): Series of cleaned text for character-level TF-IDF (e.g., from basic_clean_text).\n",
    "        texts_word (pd.Series): Series of cleaned text for word-level TF-IDF (e.g., from clean_text_semantic).\n",
    "        mode (str): 'train' to fit and transform, 'test' to only transform.\n",
    "        tfidf_char_vectorizer: Fitted TfidfVectorizer for character n-grams (required for test mode).\n",
    "        tfidf_word_vectorizer: Fitted TfidfVectorizer for word n-grams (required for test mode).\n",
    "        max_tfidf_features (int): Maximum number of TF-IDF features to generate.\n",
    "        char_ngram_range (tuple): N-gram range for character-level TF-IDF.\n",
    "        word_ngram_range (tuple): N-gram range for word-level TF-IDF.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (tfidf_char_df, tfidf_word_df, tfidf_char_vectorizer, tfidf_word_vectorizer)\n",
    "            - tfidf_char_df: DataFrame with character TF-IDF features.\n",
    "            - tfidf_word_df: DataFrame with word TF-IDF features.\n",
    "            - tfidf_char_vectorizer: Fitted (train) or input (test) character vectorizer.\n",
    "            - tfidf_word_vectorizer: Fitted (train) or input (test) word vectorizer.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If mode is 'test' and vectorizers are not provided, or if mode is invalid.\n",
    "        ValueError: If indices of texts_char and texts_word do not match.\n",
    "    \"\"\"\n",
    "    # Validate mode\n",
    "    if mode not in ['train', 'test']:\n",
    "        raise ValueError(\"Mode must be 'train' or 'test'\")\n",
    "\n",
    "    # Validate vectorizers for test mode\n",
    "    if mode == 'test' and (tfidf_char_vectorizer is None or tfidf_word_vectorizer is None):\n",
    "        raise ValueError(\"Fitted vectorizers must be provided for test mode\")\n",
    "\n",
    "    # Validate index alignment\n",
    "    if not texts_char.index.equals(texts_word.index):\n",
    "        raise ValueError(\"Indices of texts_char and texts_word must match\")\n",
    "\n",
    "    # Initialize vectorizers for training mode\n",
    "    if mode == 'train':\n",
    "        tfidf_char_vectorizer = TfidfVectorizer(\n",
    "            analyzer=\"char\",\n",
    "            ngram_range=char_ngram_range,\n",
    "            max_features=max_tfidf_features\n",
    "        )\n",
    "        tfidf_word_vectorizer = TfidfVectorizer(\n",
    "            analyzer=\"word\",\n",
    "            ngram_range=word_ngram_range,\n",
    "            max_features=max_tfidf_features\n",
    "        )\n",
    "\n",
    "    # Transform texts (fit_transform for train, transform for test)\n",
    "    if mode == 'train':\n",
    "        tfidf_char_matrix = tfidf_char_vectorizer.fit_transform(texts_char)\n",
    "        tfidf_word_matrix = tfidf_word_vectorizer.fit_transform(texts_word)\n",
    "    else:\n",
    "        tfidf_char_matrix = tfidf_char_vectorizer.transform(texts_char)\n",
    "        tfidf_word_matrix = tfidf_word_vectorizer.transform(texts_word)\n",
    "\n",
    "    # Convert to DataFrames with feature names and preserve index\n",
    "    tfidf_char_df = pd.DataFrame(\n",
    "        tfidf_char_matrix.toarray(),\n",
    "        columns=[f\"tfidf_char_{i}\" for i in range(tfidf_char_matrix.shape[1])],\n",
    "        index=texts_char.index\n",
    "    )\n",
    "    tfidf_word_df = pd.DataFrame(\n",
    "        tfidf_word_matrix.toarray(),\n",
    "        columns=[f\"tfidf_word_{i}\" for i in range(tfidf_word_matrix.shape[1])],\n",
    "        index=texts_word.index\n",
    "    )\n",
    "\n",
    "    return tfidf_char_df, tfidf_word_df, tfidf_char_vectorizer, tfidf_word_vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7971a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tfidf_features(clened_description, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7f156ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_clean = clened_description  # Your cleaned text Series (e.g., from basic_clean_text)\n",
    "train_texts_semantic = fast_semantic_cleaned_text  # Your semantic text Series (e.g., from clean_text_semantic)\n",
    "tfidf_char_train, tfidf_word_train, char_vectorizer, word_vectorizer = create_tfidf_features(\n",
    "    texts_char=train_texts_clean,\n",
    "    texts_word=train_texts_semantic,\n",
    "    mode='train',\n",
    "    max_tfidf_features=1000\n",
    ")\n",
    "\n",
    "# # For test data\n",
    "# test_texts_clean = pd.Series(...)  # Your cleaned test text Series\n",
    "# test_texts_semantic = pd.Series(...)  # Your semantic test text Series\n",
    "# tfidf_char_test, tfidf_word_test, _, _ = create_tfidf_features(\n",
    "#     texts_char=test_texts_clean,\n",
    "#     texts_word=test_texts_semantic,\n",
    "#     mode='test',\n",
    "#     tfidf_char_vectorizer=char_vectorizer,\n",
    "#     tfidf_word_vectorizer=word_vectorizer,\n",
    "#     max_tfidf_features=1000\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea58ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_char_0</th>\n",
       "      <th>tfidf_char_1</th>\n",
       "      <th>tfidf_char_2</th>\n",
       "      <th>tfidf_char_3</th>\n",
       "      <th>tfidf_char_4</th>\n",
       "      <th>tfidf_char_5</th>\n",
       "      <th>tfidf_char_6</th>\n",
       "      <th>tfidf_char_7</th>\n",
       "      <th>tfidf_char_8</th>\n",
       "      <th>tfidf_char_9</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_char_990</th>\n",
       "      <th>tfidf_char_991</th>\n",
       "      <th>tfidf_char_992</th>\n",
       "      <th>tfidf_char_993</th>\n",
       "      <th>tfidf_char_994</th>\n",
       "      <th>tfidf_char_995</th>\n",
       "      <th>tfidf_char_996</th>\n",
       "      <th>tfidf_char_997</th>\n",
       "      <th>tfidf_char_998</th>\n",
       "      <th>tfidf_char_999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159385</th>\n",
       "      <td>0.101434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064846</td>\n",
       "      <td>0.066245</td>\n",
       "      <td>0.066317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288616</th>\n",
       "      <td>0.049980</td>\n",
       "      <td>0.148691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04170</td>\n",
       "      <td>0.045871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108090</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415607</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.040189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332391</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054698</td>\n",
       "      <td>0.072564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.042379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tfidf_char_0  tfidf_char_1  tfidf_char_2  tfidf_char_3  tfidf_char_4  \\\n",
       "id                                                                             \n",
       "159385      0.101434      0.000000      0.060078      0.000000           0.0   \n",
       "288616      0.049980      0.148691      0.000000      0.000000           0.0   \n",
       "108090      0.000000      0.000000      0.000000      0.000000           0.0   \n",
       "415607      0.000000      0.000000      0.000000      0.000000           0.0   \n",
       "332391      0.000000      0.000000      0.054698      0.072564           0.0   \n",
       "\n",
       "        tfidf_char_5  tfidf_char_6  tfidf_char_7  tfidf_char_8  tfidf_char_9  \\\n",
       "id                                                                             \n",
       "159385           0.0      0.064846      0.066245      0.066317           0.0   \n",
       "288616           0.0      0.000000      0.000000      0.000000           0.0   \n",
       "108090           0.0      0.000000      0.000000      0.000000           0.0   \n",
       "415607           0.0      0.000000      0.000000      0.000000           0.0   \n",
       "332391           0.0      0.000000      0.000000      0.000000           0.0   \n",
       "\n",
       "        ...  tfidf_char_990  tfidf_char_991  tfidf_char_992  tfidf_char_993  \\\n",
       "id      ...                                                                   \n",
       "159385  ...             0.0         0.08463        0.000000             0.0   \n",
       "288616  ...             0.0         0.04170        0.045871             0.0   \n",
       "108090  ...             0.0         0.00000        0.000000             0.0   \n",
       "415607  ...             0.0         0.00000        0.040189             0.0   \n",
       "332391  ...             0.0         0.00000        0.042379             0.0   \n",
       "\n",
       "        tfidf_char_994  tfidf_char_995  tfidf_char_996  tfidf_char_997  \\\n",
       "id                                                                       \n",
       "159385             0.0        0.000000             0.0             0.0   \n",
       "288616             0.0        0.000000             0.0             0.0   \n",
       "108090             0.0        0.000000             0.0             0.0   \n",
       "415607             0.0        0.098485             0.0             0.0   \n",
       "332391             0.0        0.051925             0.0             0.0   \n",
       "\n",
       "        tfidf_char_998  tfidf_char_999  \n",
       "id                                      \n",
       "159385             0.0             0.0  \n",
       "288616             0.0             0.0  \n",
       "108090             0.0             0.0  \n",
       "415607             0.0             0.0  \n",
       "332391             0.0             0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19c1dd62",
   "metadata": {},
   "source": [
    "## создание всех фич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f2966568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flags_features(df: pd.DataFrame, flag_columns: list = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates binary flag features indicating None/NaN values for specified columns.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        flag_columns (list): List of column names to check for None/NaN.\n",
    "                           Defaults to ['brand_name', 'description', 'name_rus', 'CommercialTypeName4'].\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with binary columns (e.g., 'is_none_<column>') where 1 indicates\n",
    "                      None/NaN or missing column, 0 otherwise.\n",
    "    \"\"\"\n",
    "    if flag_columns is None:\n",
    "        flag_columns = ['brand_name', 'description', 'name_rus', 'CommercialTypeName4']\n",
    "    \n",
    "    none_flags = pd.DataFrame(index=df.index)\n",
    "    for col in flag_columns:\n",
    "        if col in df.columns:\n",
    "            none_flags[f'is_none_{col}'] = df[col].isna().astype(int)\n",
    "        else:\n",
    "            none_flags[f'is_none_{col}'] = 1  # If column is missing, assume all None\n",
    "    \n",
    "    return none_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f35688ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_text_features(\n",
    "    df: pd.DataFrame,\n",
    "    mode: str = 'train',\n",
    "    max_tfidf_features: int = 1000,\n",
    "    char_ngram_range=(3, 5),\n",
    "    word_ngram_range=(1, 3),\n",
    "    tfidf_char_vectorizer=None,\n",
    "    tfidf_word_vectorizer=None\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Creates all text features: basic, semantic, and TF-IDF, from df['description'].\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the 'description' column.\n",
    "        mode (str): 'train' to fit and transform, 'test' to only transform.\n",
    "        max_tfidf_features (int): Maximum number of TF-IDF features.\n",
    "        tfidf_char_vectorizer: Fitted TfidfVectorizer for character n-grams (test mode).\n",
    "        tfidf_word_vectorizer: Fitted TfidfVectorizer for word n-grams (test mode).\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (all_features_df, tfidf_char_vectorizer, tfidf_word_vectorizer)\n",
    "            - all_features_df: DataFrame with concatenated basic, semantic, and TF-IDF features.\n",
    "            - tfidf_char_vectorizer: Fitted or input character vectorizer.\n",
    "            - tfidf_word_vectorizer: Fitted or input word vectorizer.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If 'description' column is missing, mode is invalid, or vectorizers are missing in test mode.\n",
    "    \"\"\"\n",
    "    if 'description' not in df.columns:\n",
    "        raise ValueError(\"df must contain a 'description' column\")\n",
    "    if mode not in ['train', 'test']:\n",
    "        raise ValueError(\"Mode must be 'train' or 'test'\")\n",
    "    if mode == 'test' and (tfidf_char_vectorizer is None or tfidf_word_vectorizer is None):\n",
    "        raise ValueError(\"Fitted vectorizers must be provided for test mode\")\n",
    "\n",
    "    # Create None flags\n",
    "    none_flags = create_flags_features(df)\n",
    "\n",
    "    # Extract description\n",
    "    description = df['description']\n",
    "\n",
    "    # Basic cleaning\n",
    "    basic_cleaned_description = create_basic_cleaned_text(description)\n",
    "\n",
    "    # Basic text features\n",
    "    basic_text_features = create_basic_text_features(basic_cleaned_description)\n",
    "\n",
    "    # Semantic cleaning\n",
    "    semantic_cleaned_text = create_semantic_cleaned_text(basic_cleaned_description)\n",
    "\n",
    "    # Semantic features\n",
    "    semantic_text_features = create_semantic_features(semantic_cleaned_text)\n",
    "\n",
    "    # TF-IDF features\n",
    "    tfidf_char_df, tfidf_word_df, tfidf_char_vectorizer, tfidf_word_vectorizer = create_tfidf_features(\n",
    "        texts_char=basic_cleaned_description,\n",
    "        texts_word=semantic_cleaned_text,\n",
    "        mode=mode,\n",
    "        tfidf_char_vectorizer=tfidf_char_vectorizer,\n",
    "        tfidf_word_vectorizer=tfidf_word_vectorizer,\n",
    "        max_tfidf_features=max_tfidf_features,\n",
    "        char_ngram_range=char_ngram_range,\n",
    "        word_ngram_range=word_ngram_range\n",
    "    )\n",
    "\n",
    "    # Concatenate all features\n",
    "    all_features_df = pd.concat(\n",
    "        [none_flags, basic_text_features, semantic_text_features, tfidf_char_df, tfidf_word_df],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return all_features_df, tfidf_char_vectorizer, tfidf_word_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e5038734",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_train, char_vectorizer, word_vectorizer = create_all_text_features(\n",
    "    df=df_train,\n",
    "    mode='train',\n",
    "    max_tfidf_features=1000,\n",
    "    char_ngram_range=(3, 5),\n",
    "    word_ngram_range=(1, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "19323fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_none_brand_name</th>\n",
       "      <th>is_none_description</th>\n",
       "      <th>is_none_name_rus</th>\n",
       "      <th>is_none_CommercialTypeName4</th>\n",
       "      <th>has_url</th>\n",
       "      <th>has_phone</th>\n",
       "      <th>has_messenger</th>\n",
       "      <th>has_sku</th>\n",
       "      <th>desc_len_chars</th>\n",
       "      <th>desc_len_words</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_word_990</th>\n",
       "      <th>tfidf_word_991</th>\n",
       "      <th>tfidf_word_992</th>\n",
       "      <th>tfidf_word_993</th>\n",
       "      <th>tfidf_word_994</th>\n",
       "      <th>tfidf_word_995</th>\n",
       "      <th>tfidf_word_996</th>\n",
       "      <th>tfidf_word_997</th>\n",
       "      <th>tfidf_word_998</th>\n",
       "      <th>tfidf_word_999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159385</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288616</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108090</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415607</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332391</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_none_brand_name  is_none_description  is_none_name_rus  \\\n",
       "id                                                                  \n",
       "159385                   0                    0                 0   \n",
       "288616                   0                    0                 0   \n",
       "108090                   0                    0                 0   \n",
       "415607                   1                    0                 0   \n",
       "332391                   1                    0                 0   \n",
       "\n",
       "        is_none_CommercialTypeName4  has_url  has_phone  has_messenger  \\\n",
       "id                                                                       \n",
       "159385                            0      0.0        0.0            0.0   \n",
       "288616                            0      0.0        0.0            0.0   \n",
       "108090                            0      0.0        0.0            0.0   \n",
       "415607                            0      0.0        0.0            0.0   \n",
       "332391                            0      0.0        0.0            0.0   \n",
       "\n",
       "        has_sku  desc_len_chars  desc_len_words  ...  tfidf_word_990  \\\n",
       "id                                               ...                   \n",
       "159385      1.0           886.0           100.0  ...             0.0   \n",
       "288616      0.0           386.0            53.0  ...             0.0   \n",
       "108090      0.0           200.0            33.0  ...             0.0   \n",
       "415607      0.0           557.0            67.0  ...             0.0   \n",
       "332391      0.0           540.0            70.0  ...             0.0   \n",
       "\n",
       "        tfidf_word_991  tfidf_word_992  tfidf_word_993  tfidf_word_994  \\\n",
       "id                                                                       \n",
       "159385         0.00000             0.0             0.0             0.0   \n",
       "288616         0.25649             0.0             0.0             0.0   \n",
       "108090         0.00000             0.0             0.0             0.0   \n",
       "415607         0.00000             0.0             0.0             0.0   \n",
       "332391         0.00000             0.0             0.0             0.0   \n",
       "\n",
       "        tfidf_word_995  tfidf_word_996  tfidf_word_997  tfidf_word_998  \\\n",
       "id                                                                       \n",
       "159385             0.0             0.0             0.0             0.0   \n",
       "288616             0.0             0.0             0.0             0.0   \n",
       "108090             0.0             0.0             0.0             0.0   \n",
       "415607             0.0             0.0             0.0             0.0   \n",
       "332391             0.0             0.0             0.0             0.0   \n",
       "\n",
       "        tfidf_word_999  \n",
       "id                      \n",
       "159385             0.0  \n",
       "288616             0.0  \n",
       "108090             0.0  \n",
       "415607             0.0  \n",
       "332391             0.0  \n",
       "\n",
       "[5 rows x 2025 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "846c8a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_url</th>\n",
       "      <th>has_phone</th>\n",
       "      <th>has_messenger</th>\n",
       "      <th>has_sku</th>\n",
       "      <th>desc_len_chars</th>\n",
       "      <th>desc_len_words</th>\n",
       "      <th>capslock_word_count</th>\n",
       "      <th>exclamation_count</th>\n",
       "      <th>question_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_word_990</th>\n",
       "      <th>tfidf_word_991</th>\n",
       "      <th>tfidf_word_992</th>\n",
       "      <th>tfidf_word_993</th>\n",
       "      <th>tfidf_word_994</th>\n",
       "      <th>tfidf_word_995</th>\n",
       "      <th>tfidf_word_996</th>\n",
       "      <th>tfidf_word_997</th>\n",
       "      <th>tfidf_word_998</th>\n",
       "      <th>tfidf_word_999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159385</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.870000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288616</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.301887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108090</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415607</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.328358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332391</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.728571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2021 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        has_url  has_phone  has_messenger  has_sku  desc_len_chars  \\\n",
       "id                                                                   \n",
       "159385      0.0        0.0            0.0      1.0           886.0   \n",
       "288616      0.0        0.0            0.0      0.0           386.0   \n",
       "108090      0.0        0.0            0.0      0.0           200.0   \n",
       "415607      0.0        0.0            0.0      0.0           557.0   \n",
       "332391      0.0        0.0            0.0      0.0           540.0   \n",
       "\n",
       "        desc_len_words  capslock_word_count  exclamation_count  \\\n",
       "id                                                               \n",
       "159385           100.0                  1.0                0.0   \n",
       "288616            53.0                  0.0                0.0   \n",
       "108090            33.0                  0.0                0.0   \n",
       "415607            67.0                  0.0                0.0   \n",
       "332391            70.0                  0.0                0.0   \n",
       "\n",
       "        question_count  avg_word_length  ...  tfidf_word_990  tfidf_word_991  \\\n",
       "id                                       ...                                   \n",
       "159385             0.0         7.870000  ...             0.0         0.00000   \n",
       "288616             0.0         6.301887  ...             0.0         0.25649   \n",
       "108090             0.0         5.090909  ...             0.0         0.00000   \n",
       "415607             0.0         7.328358  ...             0.0         0.00000   \n",
       "332391             0.0         6.728571  ...             0.0         0.00000   \n",
       "\n",
       "        tfidf_word_992  tfidf_word_993  tfidf_word_994  tfidf_word_995  \\\n",
       "id                                                                       \n",
       "159385             0.0             0.0             0.0             0.0   \n",
       "288616             0.0             0.0             0.0             0.0   \n",
       "108090             0.0             0.0             0.0             0.0   \n",
       "415607             0.0             0.0             0.0             0.0   \n",
       "332391             0.0             0.0             0.0             0.0   \n",
       "\n",
       "        tfidf_word_996  tfidf_word_997  tfidf_word_998  tfidf_word_999  \n",
       "id                                                                      \n",
       "159385             0.0             0.0             0.0             0.0  \n",
       "288616             0.0             0.0             0.0             0.0  \n",
       "108090             0.0             0.0             0.0             0.0  \n",
       "415607             0.0             0.0             0.0             0.0  \n",
       "332391             0.0             0.0             0.0             0.0  \n",
       "\n",
       "[5 rows x 2021 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920a2a71",
   "metadata": {},
   "source": [
    "# создание текстовых + числовых фич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27cab5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import functools\n",
    "\n",
    "def timing_decorator(func):\n",
    "    \"\"\"\n",
    "    Декоратор для замера времени выполнения функции.\n",
    "    \"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Функция {func.__name__} выполнена за {execution_time:.6f} секунд\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cad74158",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_decorator\n",
    "def prepare_cleaned_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Подготавливает очищенный датасет с числовыми признаками и текстовыми фичами из description.\n",
    "    Удаляет целевую переменную 'resolution' перед обработкой.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pd.DataFrame, исходный датафрейм с колонкой description\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame с числовыми признаками (кроме resolution) и текстовыми фичами\n",
    "    \"\"\"\n",
    "    # Создаем копию датафрейма\n",
    "    df_clean = df.copy()\n",
    "    original_index = df_clean.index\n",
    "\n",
    "    # Удаляем целевую переменную 'resolution', если она есть\n",
    "    if 'resolution' in df_clean.columns:\n",
    "        df_clean = df_clean.drop(columns=['resolution'])\n",
    "\n",
    "    # Применяем очистку текста\n",
    "    df_clean[\"description_clean\"] = df_clean[\"description\"].apply(clean_text)\n",
    "    df_clean[\"description_semantic\"] = df_clean[\"description\"].apply(clean_text_semantic)\n",
    "\n",
    "    # Извлекаем структурные и семантические признаки\n",
    "    structural_features = df_clean[\"description_clean\"].apply(extract_features)\n",
    "    semantic_features = df_clean[\"description_semantic\"].apply(extract_semantic_features)\n",
    "\n",
    "    # Преобразуем признаки в датафреймы\n",
    "    structural_features_df = pd.json_normalize(structural_features).set_index(original_index)\n",
    "    semantic_features_df = pd.json_normalize(semantic_features).set_index(original_index)\n",
    "\n",
    "    # Выбираем числовые столбцы из исходного датафрейма (кроме 'resolution')\n",
    "    numeric_columns = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    numeric_columns = [col for col in numeric_columns if col != 'resolution']\n",
    "\n",
    "    # Оставляем только числовые столбцы\n",
    "    df_numeric = df_clean[numeric_columns].fillna(0)\n",
    "    \n",
    "    # Объединяем числовые столбцы с текстовыми признаками\n",
    "    df_result = pd.concat([df_numeric, structural_features_df, semantic_features_df], axis=1)\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d327afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "df_train = pd.read_csv('ml_ozon_сounterfeit_train.csv', index_col=0)\n",
    "# Подготовка очищенного датасета\n",
    "y_train = df_train['resolution']\n",
    "X_train = prepare_cleaned_dataset(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d10bed81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308417, 197198, 197198)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train), len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07687dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d88704a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197198"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0100279",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [308417, 197198]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train_split, X_val_split, y_train_split, y_val_split \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_split, y_train_split)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2782\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2782\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2784\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2785\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2786\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2787\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 514\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [308417, 197198]"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "val_pred = model.predict(X_val_split)\n",
    "val_accuracy = accuracy_score(y_val_split, val_pred)\n",
    "\n",
    "print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_val_split, val_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2bfd5acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Удаляем целевую переменную 'resolution', если она есть\n",
    "if 'resolution' in df_clean.columns:\n",
    "    df_clean = df_clean.drop(columns=['resolution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5f709ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_name</th>\n",
       "      <th>description</th>\n",
       "      <th>name_rus</th>\n",
       "      <th>CommercialTypeName4</th>\n",
       "      <th>rating_1_count</th>\n",
       "      <th>rating_2_count</th>\n",
       "      <th>rating_3_count</th>\n",
       "      <th>rating_4_count</th>\n",
       "      <th>rating_5_count</th>\n",
       "      <th>comments_published_count</th>\n",
       "      <th>...</th>\n",
       "      <th>ExemplarReturnedValueTotal7</th>\n",
       "      <th>ExemplarReturnedValueTotal30</th>\n",
       "      <th>ExemplarReturnedValueTotal90</th>\n",
       "      <th>ItemVarietyCount</th>\n",
       "      <th>ItemAvailableCount</th>\n",
       "      <th>seller_time_alive</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>SellerID</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>description_semantic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159385</th>\n",
       "      <td>ACTRUM</td>\n",
       "      <td>Мешки пылесборники для пылесоса PHILIPS, 10 шт...</td>\n",
       "      <td>Мешки для пылесоса PHILIPS TRIATLON, синтетиче...</td>\n",
       "      <td>Пылесборник</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>730.171845</td>\n",
       "      <td>896.528847</td>\n",
       "      <td>1043.118191</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>78312</td>\n",
       "      <td>1218</td>\n",
       "      <td>Мешки пылесборники для пылесоса PHILIPS, 10 шт...</td>\n",
       "      <td>мешок пылесборник пылесос philips шт синтетиче...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288616</th>\n",
       "      <td>Red Line</td>\n",
       "      <td>Защитная силиконовая крышка обьектива GoPro He...</td>\n",
       "      <td>Защитная крышка Redline на экшн-камеру GoPro (...</td>\n",
       "      <td>Крышка для объектива</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>993.043882</td>\n",
       "      <td>1137.421611</td>\n",
       "      <td>1188.608000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1757.0</td>\n",
       "      <td>141999</td>\n",
       "      <td>1374</td>\n",
       "      <td>Защитная силиконовая крышка обьектива GoPro He...</td>\n",
       "      <td>защитный силиконовый крышка обьектив gopro her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108090</th>\n",
       "      <td>Talwar Brothers</td>\n",
       "      <td>Плоский медиатор из кости толщиной 0.6 мм&lt;br/&gt;...</td>\n",
       "      <td>Медиатор для гитары Acura GP-PB6</td>\n",
       "      <td>Аксессуар для музыкального инструмента</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>800.822138</td>\n",
       "      <td>1174.069505</td>\n",
       "      <td>1224.798286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1722.0</td>\n",
       "      <td>53306</td>\n",
       "      <td>1448</td>\n",
       "      <td>Плоский медиатор из кости толщиной 0.6 мм Плос...</td>\n",
       "      <td>плоский медиатор кость толщина мм плоский меди...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415607</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Игра Sonic Frontiers для PlayStation 5, русски...</td>\n",
       "      <td>Игра Sonic Frontiers для PlayStation 5, русски...</td>\n",
       "      <td>Видеоигра</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>913.530121</td>\n",
       "      <td>982.789171</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>202599</td>\n",
       "      <td>715</td>\n",
       "      <td>Игра Sonic Frontiers для PlayStation 5, русски...</td>\n",
       "      <td>игра sonic frontiers playstation русский субти...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332391</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Disney Classic Games: Aladdin and The Lion Kin...</td>\n",
       "      <td>Игра Aladdin and Lion King (PlayStation 4, анг...</td>\n",
       "      <td>Видеоигра</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>913.542170</td>\n",
       "      <td>982.783783</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>163725</td>\n",
       "      <td>715</td>\n",
       "      <td>Disney Classic Games: Aladdin and The Lion Kin...</td>\n",
       "      <td>disney classic games aladdin and the lion king...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             brand_name                                        description  \\\n",
       "id                                                                           \n",
       "159385           ACTRUM  Мешки пылесборники для пылесоса PHILIPS, 10 шт...   \n",
       "288616         Red Line  Защитная силиконовая крышка обьектива GoPro He...   \n",
       "108090  Talwar Brothers  Плоский медиатор из кости толщиной 0.6 мм<br/>...   \n",
       "415607              NaN  Игра Sonic Frontiers для PlayStation 5, русски...   \n",
       "332391              NaN  Disney Classic Games: Aladdin and The Lion Kin...   \n",
       "\n",
       "                                                 name_rus  \\\n",
       "id                                                          \n",
       "159385  Мешки для пылесоса PHILIPS TRIATLON, синтетиче...   \n",
       "288616  Защитная крышка Redline на экшн-камеру GoPro (...   \n",
       "108090                   Медиатор для гитары Acura GP-PB6   \n",
       "415607  Игра Sonic Frontiers для PlayStation 5, русски...   \n",
       "332391  Игра Aladdin and Lion King (PlayStation 4, анг...   \n",
       "\n",
       "                           CommercialTypeName4  rating_1_count  \\\n",
       "id                                                               \n",
       "159385                             Пылесборник             6.0   \n",
       "288616                    Крышка для объектива             NaN   \n",
       "108090  Аксессуар для музыкального инструмента             0.0   \n",
       "415607                               Видеоигра             NaN   \n",
       "332391                               Видеоигра             1.0   \n",
       "\n",
       "        rating_2_count  rating_3_count  rating_4_count  rating_5_count  \\\n",
       "id                                                                       \n",
       "159385             4.0             4.0             3.0            32.0   \n",
       "288616             NaN             NaN             NaN             NaN   \n",
       "108090             0.0             1.0             0.0             1.0   \n",
       "415607             NaN             NaN             NaN             NaN   \n",
       "332391             0.0             0.0             0.0             0.0   \n",
       "\n",
       "        comments_published_count  ...  ExemplarReturnedValueTotal7  \\\n",
       "id                                ...                                \n",
       "159385                       3.0  ...                   730.171845   \n",
       "288616                       NaN  ...                   993.043882   \n",
       "108090                       0.0  ...                   800.822138   \n",
       "415607                       NaN  ...                     0.000000   \n",
       "332391                       0.0  ...                     0.000000   \n",
       "\n",
       "        ExemplarReturnedValueTotal30  ExemplarReturnedValueTotal90  \\\n",
       "id                                                                   \n",
       "159385                    896.528847                   1043.118191   \n",
       "288616                   1137.421611                   1188.608000   \n",
       "108090                   1174.069505                   1224.798286   \n",
       "415607                    913.530121                    982.789171   \n",
       "332391                    913.542170                    982.783783   \n",
       "\n",
       "        ItemVarietyCount  ItemAvailableCount  seller_time_alive  ItemID  \\\n",
       "id                                                                        \n",
       "159385               1.0                 1.0             1860.0   78312   \n",
       "288616               1.0                 1.0             1757.0  141999   \n",
       "108090               1.0                 1.0             1722.0   53306   \n",
       "415607               3.0                 3.0             1692.0  202599   \n",
       "332391               3.0                 3.0             1692.0  163725   \n",
       "\n",
       "        SellerID                                  description_clean  \\\n",
       "id                                                                    \n",
       "159385      1218  Мешки пылесборники для пылесоса PHILIPS, 10 шт...   \n",
       "288616      1374  Защитная силиконовая крышка обьектива GoPro He...   \n",
       "108090      1448  Плоский медиатор из кости толщиной 0.6 мм Плос...   \n",
       "415607       715  Игра Sonic Frontiers для PlayStation 5, русски...   \n",
       "332391       715  Disney Classic Games: Aladdin and The Lion Kin...   \n",
       "\n",
       "                                     description_semantic  \n",
       "id                                                         \n",
       "159385  мешок пылесборник пылесос philips шт синтетиче...  \n",
       "288616  защитный силиконовый крышка обьектив gopro her...  \n",
       "108090  плоский медиатор кость толщина мм плоский меди...  \n",
       "415607  игра sonic frontiers playstation русский субти...  \n",
       "332391  disney classic games aladdin and the lion king...  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4088ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"description_clean\"] = df_clean[\"description\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc83d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"description_semantic\"] = df_clean[\"description\"].apply(clean_text_semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86b232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлекаем структурные и семантические признаки\n",
    "structural_features = df_clean[\"description_clean\"].apply(extract_features)\n",
    "semantic_features = df_clean[\"description_semantic\"].apply(extract_semantic_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dc888962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем признаки в датафреймы\n",
    "structural_features_df = pd.json_normalize(structural_features).set_index(original_index)\n",
    "semantic_features_df = pd.json_normalize(semantic_features).set_index(original_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f0b1f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197198, 197198)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(structural_features_df), len(semantic_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2221ffd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_url</th>\n",
       "      <th>has_sku</th>\n",
       "      <th>desc_len_chars</th>\n",
       "      <th>desc_len_words</th>\n",
       "      <th>capslock_word_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159385</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>886</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288616</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>386</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108090</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415607</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>557</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332391</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        has_url  has_sku  desc_len_chars  desc_len_words  capslock_word_count\n",
       "id                                                                           \n",
       "159385        0        1             886             100                    1\n",
       "288616        0        0             386              53                    0\n",
       "108090        0        0             200              33                    0\n",
       "415607        0        0             557              67                    0\n",
       "332391        0        0             540              70                    0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structural_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8475f748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_suspicious_words</th>\n",
       "      <th>suspicious_word_count</th>\n",
       "      <th>has_brand</th>\n",
       "      <th>brand_count</th>\n",
       "      <th>has_urgency_words</th>\n",
       "      <th>urgency_word_count</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159385</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288616</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.897436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108090</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415607</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.927273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332391</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.847458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        has_suspicious_words  suspicious_word_count  has_brand  brand_count  \\\n",
       "id                                                                            \n",
       "159385                     0                      0          0            0   \n",
       "288616                     0                      0          0            0   \n",
       "108090                     0                      0          0            0   \n",
       "415607                     0                      0          0            0   \n",
       "332391                     0                      0          0            0   \n",
       "\n",
       "        has_urgency_words  urgency_word_count  unique_word_ratio  \n",
       "id                                                                \n",
       "159385                  0                   0           0.315789  \n",
       "288616                  0                   0           0.897436  \n",
       "108090                  0                   0           0.666667  \n",
       "415607                  0                   0           0.927273  \n",
       "332391                  0                   0           0.847458  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc39cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_columns = [col for col in numeric_columns if col != 'resolution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b5a73be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df_clean[numeric_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc94205c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_1_count</th>\n",
       "      <th>rating_2_count</th>\n",
       "      <th>rating_3_count</th>\n",
       "      <th>rating_4_count</th>\n",
       "      <th>rating_5_count</th>\n",
       "      <th>comments_published_count</th>\n",
       "      <th>photos_published_count</th>\n",
       "      <th>videos_published_count</th>\n",
       "      <th>PriceDiscounted</th>\n",
       "      <th>item_time_alive</th>\n",
       "      <th>...</th>\n",
       "      <th>ExemplarReturnedCountTotal30</th>\n",
       "      <th>ExemplarReturnedCountTotal90</th>\n",
       "      <th>ExemplarReturnedValueTotal7</th>\n",
       "      <th>ExemplarReturnedValueTotal30</th>\n",
       "      <th>ExemplarReturnedValueTotal90</th>\n",
       "      <th>ItemVarietyCount</th>\n",
       "      <th>ItemAvailableCount</th>\n",
       "      <th>seller_time_alive</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>SellerID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159385</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>688.436773</td>\n",
       "      <td>195</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>730.171845</td>\n",
       "      <td>896.528847</td>\n",
       "      <td>1043.118191</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>78312</td>\n",
       "      <td>1218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288616</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>663.157297</td>\n",
       "      <td>972</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>993.043882</td>\n",
       "      <td>1137.421611</td>\n",
       "      <td>1188.608000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1757.0</td>\n",
       "      <td>141999</td>\n",
       "      <td>1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108090</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>606.573197</td>\n",
       "      <td>1596</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>800.822138</td>\n",
       "      <td>1174.069505</td>\n",
       "      <td>1224.798286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1722.0</td>\n",
       "      <td>53306</td>\n",
       "      <td>1448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415607</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>856.755162</td>\n",
       "      <td>386</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>913.530121</td>\n",
       "      <td>982.789171</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>202599</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332391</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>822.274833</td>\n",
       "      <td>428</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>913.542170</td>\n",
       "      <td>982.783783</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>163725</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating_1_count  rating_2_count  rating_3_count  rating_4_count  \\\n",
       "id                                                                       \n",
       "159385             6.0             4.0             4.0             3.0   \n",
       "288616             0.0             0.0             0.0             0.0   \n",
       "108090             0.0             0.0             1.0             0.0   \n",
       "415607             0.0             0.0             0.0             0.0   \n",
       "332391             1.0             0.0             0.0             0.0   \n",
       "\n",
       "        rating_5_count  comments_published_count  photos_published_count  \\\n",
       "id                                                                         \n",
       "159385            32.0                       3.0                     6.0   \n",
       "288616             0.0                       0.0                     0.0   \n",
       "108090             1.0                       0.0                     0.0   \n",
       "415607             0.0                       0.0                     0.0   \n",
       "332391             0.0                       0.0                     0.0   \n",
       "\n",
       "        videos_published_count  PriceDiscounted  item_time_alive  ...  \\\n",
       "id                                                                ...   \n",
       "159385                     0.0       688.436773              195  ...   \n",
       "288616                     0.0       663.157297              972  ...   \n",
       "108090                     0.0       606.573197             1596  ...   \n",
       "415607                     0.0       856.755162              386  ...   \n",
       "332391                     0.0       822.274833              428  ...   \n",
       "\n",
       "        ExemplarReturnedCountTotal30  ExemplarReturnedCountTotal90  \\\n",
       "id                                                                   \n",
       "159385                          11.0                          50.0   \n",
       "288616                          26.0                          54.0   \n",
       "108090                          16.0                          34.0   \n",
       "415607                           3.0                           6.0   \n",
       "332391                           3.0                           6.0   \n",
       "\n",
       "        ExemplarReturnedValueTotal7  ExemplarReturnedValueTotal30  \\\n",
       "id                                                                  \n",
       "159385                   730.171845                    896.528847   \n",
       "288616                   993.043882                   1137.421611   \n",
       "108090                   800.822138                   1174.069505   \n",
       "415607                     0.000000                    913.530121   \n",
       "332391                     0.000000                    913.542170   \n",
       "\n",
       "        ExemplarReturnedValueTotal90  ItemVarietyCount  ItemAvailableCount  \\\n",
       "id                                                                           \n",
       "159385                   1043.118191               1.0                 1.0   \n",
       "288616                   1188.608000               1.0                 1.0   \n",
       "108090                   1224.798286               1.0                 1.0   \n",
       "415607                    982.789171               3.0                 3.0   \n",
       "332391                    982.783783               3.0                 3.0   \n",
       "\n",
       "        seller_time_alive  ItemID  SellerID  \n",
       "id                                           \n",
       "159385             1860.0   78312      1218  \n",
       "288616             1757.0  141999      1374  \n",
       "108090             1722.0   53306      1448  \n",
       "415607             1692.0  202599       715  \n",
       "332391             1692.0  163725       715  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3767401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_index = df_clean.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4e040bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.concat([df_numeric, structural_features_df, semantic_features_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "78319634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197198"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0dc621be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['resolution']\n",
    "X_train_extended = df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "52d9728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def run_experiment(\n",
    "    X_train_base, \n",
    "    X_train_extended, \n",
    "    y_train, \n",
    "    model_base, \n",
    "    model_extend,\n",
    "    descriptions_clean,       # очищенный текст для символьного tfidf\n",
    "    descriptions_semantic,    # очищенный текст для словного tfidf\n",
    "    max_tfidf_features=1000\n",
    "):\n",
    "    # Разделение на train/val\n",
    "    (\n",
    "        X_train_base_split, X_val_base_split,\n",
    "        X_train_ext_split, X_val_ext_split,\n",
    "        y_train_split, y_val_split,\n",
    "        desc_train_clean, desc_val_clean,\n",
    "        desc_train_sem, desc_val_sem\n",
    "    ) = train_test_split(\n",
    "        X_train_base, X_train_extended, y_train,\n",
    "        descriptions_clean, descriptions_semantic,\n",
    "        test_size=0.2, random_state=42, stratify=y_train\n",
    "    )\n",
    "\n",
    "    # === TF-IDF: символьные n-граммы ===\n",
    "    tfidf_char = TfidfVectorizer(analyzer=\"char\", ngram_range=(3, 5), max_features=max_tfidf_features)\n",
    "    tfidf_char_train = tfidf_char.fit_transform(desc_train_clean)\n",
    "    tfidf_char_val = tfidf_char.transform(desc_val_clean)\n",
    "\n",
    "    tfidf_char_train_df = pd.DataFrame(tfidf_char_train.toarray(),\n",
    "                                       columns=[f\"tfidf_char_{i}\" for i in range(tfidf_char_train.shape[1])],\n",
    "                                       index=X_train_base_split.index)\n",
    "    tfidf_char_val_df = pd.DataFrame(tfidf_char_val.toarray(),\n",
    "                                     columns=[f\"tfidf_char_{i}\" for i in range(tfidf_char_val.shape[1])],\n",
    "                                     index=X_val_base_split.index)\n",
    "\n",
    "    # === TF-IDF: словные n-граммы ===\n",
    "    tfidf_word = TfidfVectorizer(analyzer=\"word\", ngram_range=(1, 3), max_features=max_tfidf_features)\n",
    "    tfidf_word_train = tfidf_word.fit_transform(desc_train_sem)\n",
    "    tfidf_word_val = tfidf_word.transform(desc_val_sem)\n",
    "\n",
    "    tfidf_word_train_df = pd.DataFrame(tfidf_word_train.toarray(),\n",
    "                                       columns=[f\"tfidf_word_{i}\" for i in range(tfidf_word_train.shape[1])],\n",
    "                                       index=X_train_base_split.index)\n",
    "    tfidf_word_val_df = pd.DataFrame(tfidf_word_val.toarray(),\n",
    "                                     columns=[f\"tfidf_word_{i}\" for i in range(tfidf_word_val.shape[1])],\n",
    "                                     index=X_val_base_split.index)\n",
    "\n",
    "    # === Дополняем extended-признаки TF-IDF ===\n",
    "    X_train_ext_split = pd.concat([X_train_ext_split, tfidf_char_train_df, tfidf_word_train_df], axis=1)\n",
    "    X_val_ext_split = pd.concat([X_val_ext_split, tfidf_char_val_df, tfidf_word_val_df], axis=1)\n",
    "\n",
    "    # === Базовая модель (без tfidf) ===\n",
    "    model_base.fit(X_train_base_split, y_train_split)\n",
    "    val_pred_base = model_base.predict(X_val_base_split)\n",
    "    val_f1_base = f1_score(y_val_split, val_pred_base, pos_label=1)\n",
    "\n",
    "    # === Расширенная модель (с tfidf) ===\n",
    "    model_extend.fit(X_train_ext_split, y_train_split)\n",
    "    val_pred_ext = model_extend.predict(X_val_ext_split)\n",
    "    val_f1_ext = f1_score(y_val_split, val_pred_ext, pos_label=1)\n",
    "\n",
    "    # === Вывод ===\n",
    "    print(\"=== Базовый набор (только числовые признаки) ===\")\n",
    "    print(f\"Validation f1: {val_f1_base:.6f}\")\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_val_split, val_pred_base))\n",
    "    print()\n",
    "\n",
    "    print(\"=== Расширенный набор (числовые + tfidf признаки) ===\")\n",
    "    print(f\"Validation f1: {val_f1_ext:.6f}\")\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_val_split, val_pred_ext))\n",
    "    print()\n",
    "\n",
    "    print(f\"Улучшение f1: {(val_f1_ext - val_f1_base):.6f}\")\n",
    "\n",
    "    return tfidf_char, tfidf_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b6a5b4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_1_count</th>\n",
       "      <th>rating_2_count</th>\n",
       "      <th>rating_3_count</th>\n",
       "      <th>rating_4_count</th>\n",
       "      <th>rating_5_count</th>\n",
       "      <th>comments_published_count</th>\n",
       "      <th>photos_published_count</th>\n",
       "      <th>videos_published_count</th>\n",
       "      <th>PriceDiscounted</th>\n",
       "      <th>item_time_alive</th>\n",
       "      <th>...</th>\n",
       "      <th>desc_len_chars</th>\n",
       "      <th>desc_len_words</th>\n",
       "      <th>capslock_word_count</th>\n",
       "      <th>has_suspicious_words</th>\n",
       "      <th>suspicious_word_count</th>\n",
       "      <th>has_brand</th>\n",
       "      <th>brand_count</th>\n",
       "      <th>has_urgency_words</th>\n",
       "      <th>urgency_word_count</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159385</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>688.436773</td>\n",
       "      <td>195</td>\n",
       "      <td>...</td>\n",
       "      <td>886</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288616</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>663.157297</td>\n",
       "      <td>972</td>\n",
       "      <td>...</td>\n",
       "      <td>386</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.897436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108090</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>606.573197</td>\n",
       "      <td>1596</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415607</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>856.755162</td>\n",
       "      <td>386</td>\n",
       "      <td>...</td>\n",
       "      <td>557</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.927273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332391</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>822.274833</td>\n",
       "      <td>428</td>\n",
       "      <td>...</td>\n",
       "      <td>540</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.847458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating_1_count  rating_2_count  rating_3_count  rating_4_count  \\\n",
       "id                                                                       \n",
       "159385             6.0             4.0             4.0             3.0   \n",
       "288616             0.0             0.0             0.0             0.0   \n",
       "108090             0.0             0.0             1.0             0.0   \n",
       "415607             0.0             0.0             0.0             0.0   \n",
       "332391             1.0             0.0             0.0             0.0   \n",
       "\n",
       "        rating_5_count  comments_published_count  photos_published_count  \\\n",
       "id                                                                         \n",
       "159385            32.0                       3.0                     6.0   \n",
       "288616             0.0                       0.0                     0.0   \n",
       "108090             1.0                       0.0                     0.0   \n",
       "415607             0.0                       0.0                     0.0   \n",
       "332391             0.0                       0.0                     0.0   \n",
       "\n",
       "        videos_published_count  PriceDiscounted  item_time_alive  ...  \\\n",
       "id                                                                ...   \n",
       "159385                     0.0       688.436773              195  ...   \n",
       "288616                     0.0       663.157297              972  ...   \n",
       "108090                     0.0       606.573197             1596  ...   \n",
       "415607                     0.0       856.755162              386  ...   \n",
       "332391                     0.0       822.274833              428  ...   \n",
       "\n",
       "        desc_len_chars  desc_len_words  capslock_word_count  \\\n",
       "id                                                            \n",
       "159385             886             100                    1   \n",
       "288616             386              53                    0   \n",
       "108090             200              33                    0   \n",
       "415607             557              67                    0   \n",
       "332391             540              70                    0   \n",
       "\n",
       "        has_suspicious_words  suspicious_word_count  has_brand  brand_count  \\\n",
       "id                                                                            \n",
       "159385                     0                      0          0            0   \n",
       "288616                     0                      0          0            0   \n",
       "108090                     0                      0          0            0   \n",
       "415607                     0                      0          0            0   \n",
       "332391                     0                      0          0            0   \n",
       "\n",
       "        has_urgency_words  urgency_word_count  unique_word_ratio  \n",
       "id                                                                \n",
       "159385                  0                   0           0.315789  \n",
       "288616                  0                   0           0.897436  \n",
       "108090                  0                   0           0.666667  \n",
       "415607                  0                   0           0.927273  \n",
       "332391                  0                   0           0.847458  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_extended.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "490475d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_base = df_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ccae260c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_1_count</th>\n",
       "      <th>rating_2_count</th>\n",
       "      <th>rating_3_count</th>\n",
       "      <th>rating_4_count</th>\n",
       "      <th>rating_5_count</th>\n",
       "      <th>comments_published_count</th>\n",
       "      <th>photos_published_count</th>\n",
       "      <th>videos_published_count</th>\n",
       "      <th>PriceDiscounted</th>\n",
       "      <th>item_time_alive</th>\n",
       "      <th>...</th>\n",
       "      <th>ExemplarReturnedCountTotal30</th>\n",
       "      <th>ExemplarReturnedCountTotal90</th>\n",
       "      <th>ExemplarReturnedValueTotal7</th>\n",
       "      <th>ExemplarReturnedValueTotal30</th>\n",
       "      <th>ExemplarReturnedValueTotal90</th>\n",
       "      <th>ItemVarietyCount</th>\n",
       "      <th>ItemAvailableCount</th>\n",
       "      <th>seller_time_alive</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>SellerID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159385</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>688.436773</td>\n",
       "      <td>195</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>730.171845</td>\n",
       "      <td>896.528847</td>\n",
       "      <td>1043.118191</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>78312</td>\n",
       "      <td>1218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288616</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>663.157297</td>\n",
       "      <td>972</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>993.043882</td>\n",
       "      <td>1137.421611</td>\n",
       "      <td>1188.608000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1757.0</td>\n",
       "      <td>141999</td>\n",
       "      <td>1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108090</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>606.573197</td>\n",
       "      <td>1596</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>800.822138</td>\n",
       "      <td>1174.069505</td>\n",
       "      <td>1224.798286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1722.0</td>\n",
       "      <td>53306</td>\n",
       "      <td>1448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415607</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>856.755162</td>\n",
       "      <td>386</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>913.530121</td>\n",
       "      <td>982.789171</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>202599</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332391</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>822.274833</td>\n",
       "      <td>428</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>913.542170</td>\n",
       "      <td>982.783783</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>163725</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating_1_count  rating_2_count  rating_3_count  rating_4_count  \\\n",
       "id                                                                       \n",
       "159385             6.0             4.0             4.0             3.0   \n",
       "288616             0.0             0.0             0.0             0.0   \n",
       "108090             0.0             0.0             1.0             0.0   \n",
       "415607             0.0             0.0             0.0             0.0   \n",
       "332391             1.0             0.0             0.0             0.0   \n",
       "\n",
       "        rating_5_count  comments_published_count  photos_published_count  \\\n",
       "id                                                                         \n",
       "159385            32.0                       3.0                     6.0   \n",
       "288616             0.0                       0.0                     0.0   \n",
       "108090             1.0                       0.0                     0.0   \n",
       "415607             0.0                       0.0                     0.0   \n",
       "332391             0.0                       0.0                     0.0   \n",
       "\n",
       "        videos_published_count  PriceDiscounted  item_time_alive  ...  \\\n",
       "id                                                                ...   \n",
       "159385                     0.0       688.436773              195  ...   \n",
       "288616                     0.0       663.157297              972  ...   \n",
       "108090                     0.0       606.573197             1596  ...   \n",
       "415607                     0.0       856.755162              386  ...   \n",
       "332391                     0.0       822.274833              428  ...   \n",
       "\n",
       "        ExemplarReturnedCountTotal30  ExemplarReturnedCountTotal90  \\\n",
       "id                                                                   \n",
       "159385                          11.0                          50.0   \n",
       "288616                          26.0                          54.0   \n",
       "108090                          16.0                          34.0   \n",
       "415607                           3.0                           6.0   \n",
       "332391                           3.0                           6.0   \n",
       "\n",
       "        ExemplarReturnedValueTotal7  ExemplarReturnedValueTotal30  \\\n",
       "id                                                                  \n",
       "159385                   730.171845                    896.528847   \n",
       "288616                   993.043882                   1137.421611   \n",
       "108090                   800.822138                   1174.069505   \n",
       "415607                     0.000000                    913.530121   \n",
       "332391                     0.000000                    913.542170   \n",
       "\n",
       "        ExemplarReturnedValueTotal90  ItemVarietyCount  ItemAvailableCount  \\\n",
       "id                                                                           \n",
       "159385                   1043.118191               1.0                 1.0   \n",
       "288616                   1188.608000               1.0                 1.0   \n",
       "108090                   1224.798286               1.0                 1.0   \n",
       "415607                    982.789171               3.0                 3.0   \n",
       "332391                    982.783783               3.0                 3.0   \n",
       "\n",
       "        seller_time_alive  ItemID  SellerID  \n",
       "id                                           \n",
       "159385             1860.0   78312      1218  \n",
       "288616             1757.0  141999      1374  \n",
       "108090             1722.0   53306      1448  \n",
       "415607             1692.0  202599       715  \n",
       "332391             1692.0  163725       715  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4af5b008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Базовый набор (только числовые признаки) ===\n",
      "Validation f1: 0.674733\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     36830\n",
      "           1       0.89      0.54      0.67      2610\n",
      "\n",
      "    accuracy                           0.97     39440\n",
      "   macro avg       0.93      0.77      0.83     39440\n",
      "weighted avg       0.96      0.97      0.96     39440\n",
      "\n",
      "\n",
      "=== Расширенный набор (числовые + текстовые признаки) ===\n",
      "Validation f1: 0.6798\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     36830\n",
      "           1       0.91      0.54      0.68      2610\n",
      "\n",
      "    accuracy                           0.97     39440\n",
      "   macro avg       0.94      0.77      0.83     39440\n",
      "weighted avg       0.96      0.97      0.96     39440\n",
      "\n",
      "\n",
      "Улучшение f1: 0.0050\n"
     ]
    }
   ],
   "source": [
    "model_base = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_ext = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "run_experiment(X_train_base, X_train_extended, y_train, model_base, model_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "81d4053f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Базовый набор (только числовые признаки) ===\n",
      "Validation f1: 0.616569\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96     36830\n",
      "           1       0.47      0.89      0.62      2610\n",
      "\n",
      "    accuracy                           0.93     39440\n",
      "   macro avg       0.73      0.91      0.79     39440\n",
      "weighted avg       0.96      0.93      0.94     39440\n",
      "\n",
      "\n",
      "=== Расширенный набор (числовые + текстовые признаки) ===\n",
      "Validation f1: 0.6156\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96     36830\n",
      "           1       0.47      0.89      0.62      2610\n",
      "\n",
      "    accuracy                           0.93     39440\n",
      "   macro avg       0.73      0.91      0.79     39440\n",
      "weighted avg       0.96      0.93      0.94     39440\n",
      "\n",
      "\n",
      "Улучшение f1: -0.0010\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model_base = CatBoostClassifier(iterations=100, random_seed=42, verbose=0, auto_class_weights='Balanced', cat_features=['ItemID', 'SellerID'])\n",
    "model_ext = CatBoostClassifier(iterations=100, random_seed=42, verbose=0, auto_class_weights='Balanced', cat_features=['ItemID', 'SellerID'])\n",
    "run_experiment(X_train_base, X_train_extended, y_train, model_base, model_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5127e64e",
   "metadata": {},
   "source": [
    "# добавить tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "47cd5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "max_tfidf_features = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3d4db792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Базовый набор (только числовые признаки) ===\n",
      "Validation f1: 0.616569\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96     36830\n",
      "           1       0.47      0.89      0.62      2610\n",
      "\n",
      "    accuracy                           0.93     39440\n",
      "   macro avg       0.73      0.91      0.79     39440\n",
      "weighted avg       0.96      0.93      0.94     39440\n",
      "\n",
      "\n",
      "=== Расширенный набор (числовые + tfidf признаки) ===\n",
      "Validation f1: 0.651605\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96     36830\n",
      "           1       0.51      0.91      0.65      2610\n",
      "\n",
      "    accuracy                           0.94     39440\n",
      "   macro avg       0.75      0.92      0.81     39440\n",
      "weighted avg       0.96      0.94      0.94     39440\n",
      "\n",
      "\n",
      "Улучшение f1: 0.035036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TfidfVectorizer(analyzer='char', max_features=1000, ngram_range=(3, 5)),\n",
       " TfidfVectorizer(max_features=1000, ngram_range=(1, 3)))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model_base = CatBoostClassifier(iterations=100, random_seed=42, verbose=0, auto_class_weights='Balanced', cat_features=['ItemID', 'SellerID'])\n",
    "model_ext = CatBoostClassifier(iterations=100, random_seed=42, verbose=0, auto_class_weights='Balanced', cat_features=['ItemID', 'SellerID'])\n",
    "run_experiment(X_train_base, X_train_extended, y_train, model_base, model_ext, df_clean[\"description_clean\"], df_clean[\"description_semantic\"], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model_base = CatBoostClassifier(iterations=100, random_seed=42, verbose=0, auto_class_weights='Balanced', cat_features=['ItemID', 'SellerID'])\n",
    "model_ext = CatBoostClassifier(iterations=100, random_seed=42, verbose=0, auto_class_weights='Balanced', cat_features=['ItemID', 'SellerID'])\n",
    "run_experiment(X_train_base, X_train_extended, y_train, model_base, model_ext, df_clean[\"description_clean\"], df_clean[\"description_semantic\"], 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98658962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db21942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02023bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model_base = CatBoostClassifier(iterations=100, random_seed=42, verbose=0, auto_class_weights='Balanced', cat_features=['ItemID', 'SellerID'])\n",
    "model_ext = CatBoostClassifier(iterations=100, random_seed=42, verbose=0, auto_class_weights='Balanced', cat_features=['ItemID', 'SellerID'])\n",
    "run_experiment(X_train_base, X_train_extended, y_train, model_base, model_ext, df_clean[\"description_clean\"], df_clean[\"description_semantic\"], 4000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
