{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e55a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4924528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/den/dev/git/ozon-e-cup-2025\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232bd4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "\n",
    "import src.preprocessing as prep\n",
    "import src.torch_modules as torch_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473ee0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random data\n",
    "N_SAMPLES = 1000\n",
    "\n",
    "\n",
    "BINARY__FEATS_DIM = 10\n",
    "META__FEATS_DIM = 50\n",
    "\n",
    "TEXT__EMB_DIM = 128\n",
    "TEXT__FEATS_DIM = 300\n",
    "\n",
    "IMG__EMB_DIM = 512\n",
    "\n",
    "\n",
    "binary_feats = np.random.randint(0, 2, size=(N_SAMPLES, BINARY__FEATS_DIM))\n",
    "meta_feats = np.random.randn(N_SAMPLES, META__FEATS_DIM)\n",
    "\n",
    "text_embs = np.random.randn(N_SAMPLES, TEXT__EMB_DIM)\n",
    "text_feats = np.random.randn(N_SAMPLES, TEXT__FEATS_DIM)\n",
    "\n",
    "img_embs = np.random.randn(N_SAMPLES, IMG__EMB_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b97f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 10), (1000, 50), (1000, 128), (1000, 300), (1000, 512))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_feats.shape, meta_feats.shape, text_embs.shape, text_feats.shape, img_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7c02f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_feats.shape[1] + meta_feats.shape[1] + text_embs.shape[1] + text_feats.shape[1] + img_embs.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad2fac4",
   "metadata": {},
   "source": [
    "# 1 - Нормализация, конкатенация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Можем делать как с изображениями\n",
    "X_all_with_imgs, meta_scaler_1, text_scaler_1 = prep.preprocess_features(\n",
    "    binary_feats=binary_feats,\n",
    "    meta_feats=meta_feats,\n",
    "    text_feats=text_feats,\n",
    "    text_embs=text_embs,\n",
    "    img_embs=img_embs,\n",
    "    fit_scalers=True,\n",
    ")\n",
    "\n",
    "# Так и без\n",
    "X_all_wo_imgs, meta_scaler_2, text_scaler_2 = prep.preprocess_features(\n",
    "    binary_feats=binary_feats,\n",
    "    meta_feats=meta_feats,\n",
    "    text_feats=text_feats,\n",
    "    text_embs=text_embs,\n",
    "    fit_scalers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73caa22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_all_with_imgs), len(X_all_wo_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdcc1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 1002), (1000, 489))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(X_all_with_imgs, axis=-1).shape, np.concatenate(X_all_wo_imgs, axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc5ce28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(StandardScaler(), (50,), (50,), StandardScaler(), (300,), (300,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Скейлеры, которые можем подавать и на валидации/тесте\n",
    "meta_scaler_1, meta_scaler_1.mean_.shape, meta_scaler_1.scale_.shape, text_scaler_1, text_scaler_1.mean_.shape, text_scaler_1.scale_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab70f6",
   "metadata": {},
   "source": [
    "# 2 - Добавим аттеншн"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a61623",
   "metadata": {},
   "source": [
    "## 2.1 легко"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a8b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 12), (1000, 50), (1000, 300), (1000, 128), (1000, 512))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Препроцессим данные\n",
    "X_all_with_imgs, meta_scaler, text_scaler = prep.preprocess_features(\n",
    "    binary_feats=binary_feats,\n",
    "    meta_feats=meta_feats,\n",
    "    text_feats=text_feats,\n",
    "    text_embs=text_embs,\n",
    "    img_embs=img_embs,\n",
    "    fit_scalers=True,\n",
    ")\n",
    "(\n",
    "    binary_feats,\n",
    "    meta_feats_prep,\n",
    "    text_presence_flag,\n",
    "    text_feats_prep,\n",
    "    text_embs_prep,\n",
    "    img_presence_flag,\n",
    "    img_embs_prep,\n",
    ") = X_all_with_imgs\n",
    "\n",
    "# Add presence flags to binary_feats\n",
    "binary_feats = np.concatenate([binary_feats, text_presence_flag, img_presence_flag], axis=1)\n",
    "\n",
    "binary_feats.shape, meta_feats_prep.shape, text_feats_prep.shape, text_embs_prep.shape, img_embs_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9341cf97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 5, 64])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Multi-modal fusion\n",
    "MMProj = torch_modules.MultiModalProjector(\n",
    "    [\n",
    "        binary_feats.shape[1],\n",
    "        meta_feats_prep.shape[1],\n",
    "        text_feats_prep.shape[1],\n",
    "        text_embs_prep.shape[1],\n",
    "        img_embs_prep.shape[1],\n",
    "    ],\n",
    "    emb_dim=64,\n",
    ")\n",
    "\n",
    "proj_embs = MMProj(\n",
    "    torch.from_numpy(binary_feats).float(),\n",
    "    torch.from_numpy(meta_feats_prep).float(),\n",
    "    torch.from_numpy(text_feats_prep).float(),\n",
    "    torch.from_numpy(text_embs_prep).float(),\n",
    "    torch.from_numpy(img_embs_prep).float(),\n",
    ")\n",
    "proj_embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f84365",
   "metadata": {},
   "source": [
    "Получили последовательность векторов, которую можем теперь подать в простенький трансформер.\n",
    "\n",
    "В MMTtransformerEncoder это уже зашито."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd9edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_tr_enc = torch_modules.MMTransformerEncoder(\n",
    "    input_dims=[\n",
    "        binary_feats.shape[1],\n",
    "        meta_feats_prep.shape[1],\n",
    "        text_feats_prep.shape[1],\n",
    "        text_embs_prep.shape[1],\n",
    "        img_embs_prep.shape[1],\n",
    "    ],\n",
    "    emb_dim=64,\n",
    "    num_heads=4,\n",
    "    num_layers=2,\n",
    "    mlp_hidden_dim=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f637ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = mm_tr_enc(\n",
    "    torch.from_numpy(binary_feats).float(),\n",
    "    torch.from_numpy(meta_feats_prep).float(),\n",
    "    torch.from_numpy(text_feats_prep).float(),\n",
    "    torch.from_numpy(text_embs_prep).float(),\n",
    "    torch.from_numpy(img_embs_prep).float(),\n",
    ")\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c3de81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "MMTransformerEncoder                          [1000]                    --\n",
       "├─MultiModalProjector: 1-1                    [1000, 5, 64]             --\n",
       "│    └─ModuleList: 2-1                        --                        --\n",
       "│    │    └─Linear: 3-1                       [1000, 64]                832\n",
       "│    │    └─Linear: 3-2                       [1000, 64]                3,264\n",
       "│    │    └─Linear: 3-3                       [1000, 64]                19,264\n",
       "│    │    └─Linear: 3-4                       [1000, 64]                8,256\n",
       "│    │    └─Linear: 3-5                       [1000, 64]                32,832\n",
       "├─ModuleList: 1-2                             --                        --\n",
       "│    └─ModuleList: 2-2                        --                        --\n",
       "│    │    └─AttentionBlock: 3-6               [1000, 5, 64]             16,704\n",
       "│    │    └─MLPBlock: 3-7                     [1000, 5, 64]             24,960\n",
       "│    └─ModuleList: 2-3                        --                        --\n",
       "│    │    └─AttentionBlock: 3-8               [1000, 5, 64]             16,704\n",
       "│    │    └─MLPBlock: 3-9                     [1000, 5, 64]             24,960\n",
       "├─RMSNorm: 1-3                                [1000, 64]                64\n",
       "├─Linear: 1-4                                 [1000, 1]                 65\n",
       "===============================================================================================\n",
       "Total params: 147,905\n",
       "Trainable params: 147,905\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 114.62\n",
       "===============================================================================================\n",
       "Input size (MB): 4.01\n",
       "Forward/backward pass size (MB): 38.92\n",
       "Params size (MB): 0.46\n",
       "Estimated Total Size (MB): 43.39\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(\n",
    "    mm_tr_enc,\n",
    "    input_data=[\n",
    "        torch.from_numpy(binary_feats).float(),\n",
    "        torch.from_numpy(meta_feats_prep).float(),\n",
    "        torch.from_numpy(text_feats_prep).float(),\n",
    "        torch.from_numpy(text_embs_prep).float(),\n",
    "        torch.from_numpy(img_embs_prep).float(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9b90e1",
   "metadata": {},
   "source": [
    "## 2.2 тяжело"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f43627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ozon-e-cup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
